{"meta":{"version":1,"warehouse":"4.0.1"},"models":{"Asset":[{"_id":"themes/Academia/source/attaches/CV.pdf","path":"attaches/CV.pdf","modified":0,"renderable":1},{"_id":"themes/Academia/source/css/index.styl","path":"css/index.styl","modified":0,"renderable":1},{"_id":"themes/Academia/source/css/user.css","path":"css/user.css","modified":0,"renderable":1},{"_id":"themes/Academia/source/css/user.styl","path":"css/user.styl","modified":0,"renderable":1},{"_id":"themes/Academia/source/js/main.js","path":"js/main.js","modified":0,"renderable":1},{"_id":"themes/Academia/source/img/myPhoto.jpg","path":"img/myPhoto.jpg","modified":0,"renderable":1},{"_id":"themes/Academia/source/img/favicon.png","path":"img/favicon.png","modified":0,"renderable":1},{"_id":"themes/Academia/source/img/profile.png","path":"img/profile.png","modified":0,"renderable":1},{"_id":"source/Projects/CoinForest.png","path":"Projects/CoinForest.png","modified":0,"renderable":0},{"_id":"source/Projects/Enchanter.png","path":"Projects/Enchanter.png","modified":0,"renderable":0},{"_id":"source/Projects/HappyDancing.png","path":"Projects/HappyDancing.png","modified":0,"renderable":0},{"_id":"source/Projects/Love-is-in-the-Air.jpg","path":"Projects/Love-is-in-the-Air.jpg","modified":0,"renderable":0},{"_id":"source/Projects/MultiStyleNST.png","path":"Projects/MultiStyleNST.png","modified":0,"renderable":0},{"_id":"source/Projects/MusicBox.jpg","path":"Projects/MusicBox.jpg","modified":0,"renderable":0},{"_id":"source/Projects/iRing.jpg","path":"Projects/iRing.jpg","modified":0,"renderable":0},{"_id":"source/CoinForest/imgs/CoinForest.png","path":"CoinForest/imgs/CoinForest.png","modified":0,"renderable":0},{"_id":"source/Enchanter/imgs/ScreenShot.png","path":"Enchanter/imgs/ScreenShot.png","modified":0,"renderable":0},{"_id":"source/Enchanter/imgs/poster.png","path":"Enchanter/imgs/poster.png","modified":0,"renderable":0},{"_id":"source/Enchanter/imgs/procedure.png","path":"Enchanter/imgs/procedure.png","modified":0,"renderable":0},{"_id":"source/MultiStyleNST/imgs/blending.png","path":"MultiStyleNST/imgs/blending.png","modified":0,"renderable":0},{"_id":"source/MultiStyleNST/imgs/compare.png","path":"MultiStyleNST/imgs/compare.png","modified":0,"renderable":0},{"_id":"source/MultiStyleNST/imgs/model_architecture.png","path":"MultiStyleNST/imgs/model_architecture.png","modified":0,"renderable":0},{"_id":"source/MultiStyleNST/imgs/model_video.png","path":"MultiStyleNST/imgs/model_video.png","modified":0,"renderable":0},{"_id":"source/MultiStyleNST/imgs/result_1.png","path":"MultiStyleNST/imgs/result_1.png","modified":0,"renderable":0},{"_id":"source/MultiStyleNST/imgs/video_1.gif","path":"MultiStyleNST/imgs/video_1.gif","modified":0,"renderable":0},{"_id":"source/MultiStyleNST/imgs/result_2.png","path":"MultiStyleNST/imgs/result_2.png","modified":0,"renderable":0},{"_id":"source/MultiStyleNST/imgs/video_2.gif","path":"MultiStyleNST/imgs/video_2.gif","modified":0,"renderable":0},{"_id":"source/HappyDancing/imgs/HappyDancing.png","path":"HappyDancing/imgs/HappyDancing.png","modified":0,"renderable":0},{"_id":"source/MusicBox/imgs/1.jpg","path":"MusicBox/imgs/1.jpg","modified":0,"renderable":0},{"_id":"source/MusicBox/imgs/4.jpg","path":"MusicBox/imgs/4.jpg","modified":0,"renderable":0},{"_id":"source/MusicBox/imgs/2.jpg","path":"MusicBox/imgs/2.jpg","modified":0,"renderable":0},{"_id":"source/MusicBox/imgs/3.jpg","path":"MusicBox/imgs/3.jpg","modified":0,"renderable":0},{"_id":"source/MusicBox/imgs/ConvertEx.png","path":"MusicBox/imgs/ConvertEx.png","modified":0,"renderable":0},{"_id":"source/MusicBox/imgs/importLibrary.png","path":"MusicBox/imgs/importLibrary.png","modified":0,"renderable":0},{"_id":"source/MusicBox/imgs/schematic.png","path":"MusicBox/imgs/schematic.png","modified":0,"renderable":0},{"_id":"source/iRing/imgs/bending.png","path":"iRing/imgs/bending.png","modified":0,"renderable":0},{"_id":"source/iRing/imgs/iRing.jpg","path":"iRing/imgs/iRing.jpg","modified":0,"renderable":0},{"_id":"source/iRing/imgs/histogram.jpeg","path":"iRing/imgs/histogram.jpeg","modified":0,"renderable":0},{"_id":"source/iRing/imgs/notWearing.png","path":"iRing/imgs/notWearing.png","modified":0,"renderable":0},{"_id":"source/iRing/imgs/orientation.jpeg","path":"iRing/imgs/orientation.jpeg","modified":0,"renderable":0},{"_id":"source/iRing/imgs/pressing-1.png","path":"iRing/imgs/pressing-1.png","modified":0,"renderable":0},{"_id":"source/iRing/imgs/pressing-2.png","path":"iRing/imgs/pressing-2.png","modified":0,"renderable":0},{"_id":"source/iRing/imgs/wearing.png","path":"iRing/imgs/wearing.png","modified":0,"renderable":0}],"Cache":[{"_id":"source/CoinForest/index.md","hash":"0056df2d58b94283ec1cdcf62455856701d1cc57","modified":1705067157800},{"_id":"source/Enchanter/.DS_Store","hash":"3d1197ca55a90780b9ee5b6a92ce6d899704bce3","modified":1604468765259},{"_id":"source/.DS_Store","hash":"1d6ae3af747977ddf02b64f5eb220a96707825c7","modified":1606389430215},{"_id":"source/CoinForest/.DS_Store","hash":"4b8cf601ec69075a2ae60668043aff8743c8941b","modified":1604462238181},{"_id":"source/MultiStyleNST/index.md","hash":"f8cfb3451dc83ea163d622e7b52993ece06e3c66","modified":1705067157916},{"_id":"source/Enchanter/index.md","hash":"ab22642bc5535ef16d10738f892512b9a494a3b6","modified":1705067157818},{"_id":"source/MultiStyleNST/.DS_Store","hash":"d07ae3232c1afde27ae5517910699c2d61d74aed","modified":1604319884439},{"_id":"source/HappyDancing/.DS_Store","hash":"9c4b1c4b466797e58461556d69e224214d4f953b","modified":1604463632114},{"_id":"source/HappyDancing/index.md","hash":"6ff8ee0f3d28616a386ede758ca0a27e429b09e5","modified":1705067157823},{"_id":"source/MusicBox/.DS_Store","hash":"cac67ca2c210d9844246974589ce9b4879a018a2","modified":1604382070306},{"_id":"source/MusicBox/index.md","hash":"c44a6e28a7192856971e2c3ac589376b280cea24","modified":1705067157921},{"_id":"source/Resume/index.md","hash":"c00cd2898873219eb03618b263d3269ad6d02d7f","modified":1705331063842},{"_id":"source/Projects/.DS_Store","hash":"a7104ec9c498d297eccaddd899bee5c47123b89e","modified":1604468210350},{"_id":"source/Projects/Love-is-in-the-Air.jpg","hash":"e265892766aba69bdb186a5229ab97905a4772f4","modified":1604290185741},{"_id":"source/Projects/index.md","hash":"10bf0cebea36c820bf1c5da3568940a6c5816d7d","modified":1705329240001},{"_id":"source/Thesis/index.md","hash":"0959472fc30c961e5956f932c52e7cf7fc93bbcd","modified":1705329285748},{"_id":"source/_posts/.DS_Store","hash":"47dc2ce25a72c6399e3f1089d0508867025adeb1","modified":1606389430214},{"_id":"source/_posts/home.md","hash":"7e3fd5116f4458baa7e5d4291258379741cbdb47","modified":1705330525477},{"_id":"source/iRing/.DS_Store","hash":"e28bd50b3a5f29b81856ca5b63c5875750f35e9a","modified":1604406291910},{"_id":"source/iRing/index.md","hash":"6a71ef2f5bfe3648ce5efb05afcd7c82a15f39f3","modified":1705067157964},{"_id":"source/Enchanter/imgs/.DS_Store","hash":"df2fbeb1400acda0909a32c1cf6bf492f1121e07","modified":1604468772612},{"_id":"source/MusicBox/imgs/importLibrary.png","hash":"7f10530145bc2f59b701f3558b32e68eaff3f8f0","modified":1604376141061},{"_id":"source/iRing/imgs/histogram.jpeg","hash":"22ec90cd71ace2370eb32bd27e47872c36a8678c","modified":1604404152848},{"_id":"source/iRing/imgs/orientation.jpeg","hash":"c8b08cc4d8652d611102cbf59fa50971ea252b37","modified":1604404166910},{"_id":"source/MultiStyleNST/imgs/model_video.png","hash":"3429d840ebafa4377a047a89c35a865896eed85a","modified":1603976972000},{"_id":"source/MusicBox/imgs/ConvertEx.png","hash":"53de86479b535482d1afe7a19ea9236e35e1aa84","modified":1604376503705},{"_id":"source/Projects/MusicBox.jpg","hash":"361cbb2fecfffc0aaab2bc9407e4fdc0e54cc271","modified":1604371032412},{"_id":"source/MusicBox/imgs/1.jpg","hash":"caf5aa664a6cfea310de72cbde43ea319fcc2149","modified":1604371032285},{"_id":"source/MusicBox/imgs/4.jpg","hash":"27ef15ea9845577a27521609dd42d6876b5e5ab9","modified":1604371032512},{"_id":"source/MusicBox/imgs/3.jpg","hash":"361cbb2fecfffc0aaab2bc9407e4fdc0e54cc271","modified":1604371032412},{"_id":"source/iRing/imgs/notWearing.png","hash":"36065ee07da2832ccdfb53a5cb62484d60f36df4","modified":1604403386619},{"_id":"themes/Academia/.DS_Store","hash":"26302bde2508bb3498a2ec39bad6dff180bf66f7","modified":1604653832776},{"_id":"themes/Academia/README.md","hash":"d8637154a5236d75e7492f0dd5a2a9222fadfaa6","modified":1705067157965},{"_id":"themes/Academia/layout/index.pug","hash":"d7f5491090f6fba6b00efea99fbb2ab6191c8052","modified":1604222877202},{"_id":"themes/Academia/scripts/datafile.js","hash":"47ee0429c087dc0472b8ba841230139941db4003","modified":1604222877203},{"_id":"themes/Academia/_config.yml","hash":"9e5c04adc7363db849d583960523c3b9fde8bd26","modified":1705333316199},{"_id":"themes/Academia/LICENSE","hash":"b7f59a58a8f51043543be807d0995d48dde73b15","modified":1705067157965},{"_id":"themes/Academia/layout/includes/mobile-nav.pug","hash":"3cf266fc93890fe8aabf75eee8d30a437f016539","modified":1604222877201},{"_id":"themes/Academia/layout/page.pug","hash":"2c154231297e2e36102e6031dadae65b5c1a564c","modified":1604222877203},{"_id":"themes/Academia/layout/includes/footer.pug","hash":"c5e6a83a8ba61bb2c15b1314cf4299dfe579b965","modified":1604222877201},{"_id":"themes/Academia/source/.DS_Store","hash":"2052f5770e0c8ba2759417ec68161b679148f50a","modified":1604653832777},{"_id":"themes/Academia/layout/includes/side-card.pug","hash":"84ba9f57114fd847afb41d3bb5e5cbd51d2efa5b","modified":1604222877202},{"_id":"themes/Academia/source/attaches/.DS_Store","hash":"df2fbeb1400acda0909a32c1cf6bf492f1121e07","modified":1604555460164},{"_id":"themes/Academia/layout/includes/header.pug","hash":"564c213f9eea287f9d210cbe2251c815ba9562da","modified":1604222877201},{"_id":"themes/Academia/layout/includes/layout.pug","hash":"8d2fc30d5d8961a11e25e691abfda920a377df1b","modified":1604222877201},{"_id":"themes/Academia/source/css/.DS_Store","hash":"0f9a6c94a1ea063e1223516216592af313b8395a","modified":1604224783942},{"_id":"themes/Academia/source/css/user.css","hash":"40ce127398f9a8ad4279f68125dae88f9218b304","modified":1705067157971},{"_id":"themes/Academia/source/css/index.styl","hash":"978ac6e8ca1fea0ad7bd8347e44d67e5a48e21e8","modified":1604222877205},{"_id":"themes/Academia/source/js/main.js","hash":"3602dddaad6d61d18a521fcddd500921959237b2","modified":1604222877207},{"_id":"themes/Academia/source/css/user.styl","hash":"40ce127398f9a8ad4279f68125dae88f9218b304","modified":1705067157971},{"_id":"themes/Academia/source/img/.DS_Store","hash":"df2fbeb1400acda0909a32c1cf6bf492f1121e07","modified":1604556506003},{"_id":"themes/Academia/source/css/_highlight/highlight.styl","hash":"618e8fea76b57dd6e79fa0fb4557ea1907bf7d1b","modified":1604222877205},{"_id":"themes/Academia/source/img/favicon.png","hash":"bdb5d7261f7b99f05a3680a7701de96e81fb7a96","modified":1604222877205},{"_id":"themes/Academia/source/img/profile.png","hash":"5358b67cb793572aac422e23ad7db401e1c7ac2b","modified":1604222877206},{"_id":"themes/Academia/source/img/myPhoto.jpg","hash":"f9b3faa5e8b4e676ed1a361f6131bcc38b5d2f2a","modified":1565456256430},{"_id":"source/Projects/iRing.jpg","hash":"387a6703d429d8580d285122cbba4ac18eb90d77","modified":1604402382313},{"_id":"source/Enchanter/imgs/procedure.png","hash":"8d897dd07c1b5a246429058efa46eea3ff328f18","modified":1604292745069},{"_id":"source/MusicBox/imgs/2.jpg","hash":"caed212c7f47a627c0d670d0809dca0604ff2bf1","modified":1604371032550},{"_id":"source/iRing/imgs/iRing.jpg","hash":"387a6703d429d8580d285122cbba4ac18eb90d77","modified":1604402382313},{"_id":"source/iRing/imgs/pressing-1.png","hash":"5da644074f0b1e5290eeec203c0829926a38bdc0","modified":1604403352750},{"_id":"source/iRing/imgs/pressing-2.png","hash":"d6cdfbf29da0e451ec898dc58a8857de27024e81","modified":1604403365038},{"_id":"source/iRing/imgs/wearing.png","hash":"e9e06fa1ae8fdcc04e58abca02526adf36a2a66c","modified":1604403411423},{"_id":"source/MusicBox/imgs/schematic.png","hash":"1bea725c8184c973d98e4fe123dfaf8485995b4b","modified":1604374317591},{"_id":"source/MultiStyleNST/imgs/model_architecture.png","hash":"bbedcdf2535bf5f8aa90483209709c0e995499b9","modified":1603976972000},{"_id":"source/iRing/imgs/bending.png","hash":"79cc97cd309a1e6da2fae338d43f36b9b85377a8","modified":1604403377400},{"_id":"source/MultiStyleNST/imgs/result_1.png","hash":"92bdae0381ecd8e9d5a9f8f7054a522becafdacf","modified":1603976972000},{"_id":"source/Projects/MultiStyleNST.png","hash":"ed197ee13c37072f0f0daca31a344b885be2a710","modified":1603976972000},{"_id":"source/MultiStyleNST/imgs/blending.png","hash":"55718f1ce795f6bc4868e789db4025ca8ccbe6b7","modified":1603976972000},{"_id":"source/MultiStyleNST/imgs/result_2.png","hash":"ed197ee13c37072f0f0daca31a344b885be2a710","modified":1603976972000},{"_id":"source/HappyDancing/imgs/HappyDancing.png","hash":"bdc2ba3c1e9e1d331bea7652304e45aa8ab6d001","modified":1604461446251},{"_id":"source/Projects/HappyDancing.png","hash":"bdc2ba3c1e9e1d331bea7652304e45aa8ab6d001","modified":1604461446251},{"_id":"themes/Academia/source/attaches/CV.pdf","hash":"230961a1b7c51dbd06f3614dfd101c0b3c2c9448","modified":1604479556253},{"_id":"source/MultiStyleNST/imgs/compare.png","hash":"f0bfafd936976d20b529304426b18a8063ea5fb8","modified":1603976972000},{"_id":"source/Enchanter/imgs/poster.png","hash":"2800a71df5950a86bd62cd8a3d2c0045e1a02c90","modified":1604468743102},{"_id":"source/Enchanter/imgs/ScreenShot.png","hash":"678e202c77c09917752c91205ead022fc2c761fc","modified":1604293504996},{"_id":"source/Projects/Enchanter.png","hash":"2800a71df5950a86bd62cd8a3d2c0045e1a02c90","modified":1604468743102},{"_id":"source/MultiStyleNST/imgs/video_2.gif","hash":"29aedfc1994a197a8fac488366fe3afc30915e05","modified":1603976972000},{"_id":"source/MultiStyleNST/imgs/video_1.gif","hash":"6cfa2a0d5e66d21f35dd12fb2cde03f490f2efb8","modified":1603976972000},{"_id":"source/CoinForest/imgs/CoinForest.png","hash":"52205868e893bf0b6fb200e1717a7ecf7ba1fd84","modified":1604461402847},{"_id":"source/Projects/CoinForest.png","hash":"52205868e893bf0b6fb200e1717a7ecf7ba1fd84","modified":1604461402847},{"_id":"public/CoinForest/index.html","hash":"32fe73a71c876ca66c4b853c3aac31deb9361700","modified":1705333323221},{"_id":"public/Enchanter/index.html","hash":"8f13d0e0b24b8afe164e624599adf540b5673222","modified":1705333323221},{"_id":"public/MultiStyleNST/index.html","hash":"72a8d599d25303a87f6607d750ee6aba2dfa9565","modified":1705333323221},{"_id":"public/HappyDancing/index.html","hash":"e17438bb22a70ab26b4679d466547a3ca189728c","modified":1705333323221},{"_id":"public/Resume/index.html","hash":"f834095e40f3528d2595c62657d3fba6722b6884","modified":1705333323221},{"_id":"public/MusicBox/index.html","hash":"b35cf80132243a51d8f23e4e1325f42df85fb1d0","modified":1705333323221},{"_id":"public/Projects/index.html","hash":"03fb224968dc7747f822850c8ceabbef6b29cd63","modified":1705333323221},{"_id":"public/Thesis/index.html","hash":"67b34fc71c3c247b7225a6aa49f13e224fd933e2","modified":1705333323221},{"_id":"public/iRing/index.html","hash":"ffafff6b9112ea9aae37a70ff667f2c8a33ec3b5","modified":1705333323221},{"_id":"public/2020/11/03/home/index.html","hash":"94fd864d786f3ff6f1214db65cc2d92e57991ba5","modified":1705333323221},{"_id":"public/index.html","hash":"fbe940c0f2ffa4b5bcccca59e89b90961223ab89","modified":1705333323221},{"_id":"public/archives/index.html","hash":"fbe940c0f2ffa4b5bcccca59e89b90961223ab89","modified":1705333323221},{"_id":"public/archives/2020/index.html","hash":"fbe940c0f2ffa4b5bcccca59e89b90961223ab89","modified":1705333323221},{"_id":"public/archives/2020/11/index.html","hash":"fbe940c0f2ffa4b5bcccca59e89b90961223ab89","modified":1705333323221},{"_id":"public/img/myPhoto.jpg","hash":"f9b3faa5e8b4e676ed1a361f6131bcc38b5d2f2a","modified":1650524289717},{"_id":"public/img/favicon.png","hash":"bdb5d7261f7b99f05a3680a7701de96e81fb7a96","modified":1650524289717},{"_id":"public/img/profile.png","hash":"5358b67cb793572aac422e23ad7db401e1c7ac2b","modified":1650524289717},{"_id":"public/Projects/Love-is-in-the-Air.jpg","hash":"e265892766aba69bdb186a5229ab97905a4772f4","modified":1650524289717},{"_id":"public/MusicBox/imgs/importLibrary.png","hash":"7f10530145bc2f59b701f3558b32e68eaff3f8f0","modified":1650524289717},{"_id":"public/iRing/imgs/histogram.jpeg","hash":"22ec90cd71ace2370eb32bd27e47872c36a8678c","modified":1650524289717},{"_id":"public/iRing/imgs/orientation.jpeg","hash":"c8b08cc4d8652d611102cbf59fa50971ea252b37","modified":1650524289717},{"_id":"public/MultiStyleNST/imgs/model_video.png","hash":"3429d840ebafa4377a047a89c35a865896eed85a","modified":1650524289717},{"_id":"public/MusicBox/imgs/ConvertEx.png","hash":"53de86479b535482d1afe7a19ea9236e35e1aa84","modified":1650524289717},{"_id":"public/js/main.js","hash":"faf9b5cfaecf81fd2027620279e083ddab481c3b","modified":1650524289717},{"_id":"public/css/user.css","hash":"dd1359bb9dd7fb58c100b5ac819911ccbd81d98f","modified":1650524289717},{"_id":"public/css/index.css","hash":"6b8aae1908ac1799aaffdce76ee5d83e4328bfe7","modified":1650524289717},{"_id":"public/Projects/MusicBox.jpg","hash":"361cbb2fecfffc0aaab2bc9407e4fdc0e54cc271","modified":1650524289717},{"_id":"public/MusicBox/imgs/1.jpg","hash":"caf5aa664a6cfea310de72cbde43ea319fcc2149","modified":1650524289717},{"_id":"public/MusicBox/imgs/3.jpg","hash":"361cbb2fecfffc0aaab2bc9407e4fdc0e54cc271","modified":1650524289717},{"_id":"public/iRing/imgs/notWearing.png","hash":"36065ee07da2832ccdfb53a5cb62484d60f36df4","modified":1650524289717},{"_id":"public/Projects/iRing.jpg","hash":"387a6703d429d8580d285122cbba4ac18eb90d77","modified":1650524289717},{"_id":"public/Enchanter/imgs/procedure.png","hash":"8d897dd07c1b5a246429058efa46eea3ff328f18","modified":1650524289717},{"_id":"public/MusicBox/imgs/2.jpg","hash":"caed212c7f47a627c0d670d0809dca0604ff2bf1","modified":1650524289717},{"_id":"public/MusicBox/imgs/4.jpg","hash":"27ef15ea9845577a27521609dd42d6876b5e5ab9","modified":1650524289717},{"_id":"public/iRing/imgs/pressing-2.png","hash":"d6cdfbf29da0e451ec898dc58a8857de27024e81","modified":1650524289717},{"_id":"public/iRing/imgs/bending.png","hash":"79cc97cd309a1e6da2fae338d43f36b9b85377a8","modified":1650524289717},{"_id":"public/iRing/imgs/iRing.jpg","hash":"387a6703d429d8580d285122cbba4ac18eb90d77","modified":1650524289717},{"_id":"public/iRing/imgs/wearing.png","hash":"e9e06fa1ae8fdcc04e58abca02526adf36a2a66c","modified":1650524289717},{"_id":"public/MusicBox/imgs/schematic.png","hash":"1bea725c8184c973d98e4fe123dfaf8485995b4b","modified":1650524289717},{"_id":"public/MultiStyleNST/imgs/model_architecture.png","hash":"bbedcdf2535bf5f8aa90483209709c0e995499b9","modified":1650524289717},{"_id":"public/iRing/imgs/pressing-1.png","hash":"5da644074f0b1e5290eeec203c0829926a38bdc0","modified":1650524289717},{"_id":"public/MultiStyleNST/imgs/result_2.png","hash":"ed197ee13c37072f0f0daca31a344b885be2a710","modified":1650524289717},{"_id":"public/MultiStyleNST/imgs/result_1.png","hash":"92bdae0381ecd8e9d5a9f8f7054a522becafdacf","modified":1650524289717},{"_id":"public/Projects/MultiStyleNST.png","hash":"ed197ee13c37072f0f0daca31a344b885be2a710","modified":1650524289717},{"_id":"public/MultiStyleNST/imgs/blending.png","hash":"55718f1ce795f6bc4868e789db4025ca8ccbe6b7","modified":1650524289717},{"_id":"public/HappyDancing/imgs/HappyDancing.png","hash":"bdc2ba3c1e9e1d331bea7652304e45aa8ab6d001","modified":1650524289717},{"_id":"public/Projects/HappyDancing.png","hash":"bdc2ba3c1e9e1d331bea7652304e45aa8ab6d001","modified":1650524289717},{"_id":"public/attaches/CV.pdf","hash":"230961a1b7c51dbd06f3614dfd101c0b3c2c9448","modified":1705120533562},{"_id":"public/MultiStyleNST/imgs/compare.png","hash":"f0bfafd936976d20b529304426b18a8063ea5fb8","modified":1650524289717},{"_id":"public/Projects/Enchanter.png","hash":"2800a71df5950a86bd62cd8a3d2c0045e1a02c90","modified":1650524289717},{"_id":"public/Enchanter/imgs/ScreenShot.png","hash":"678e202c77c09917752c91205ead022fc2c761fc","modified":1650524289717},{"_id":"public/Enchanter/imgs/poster.png","hash":"2800a71df5950a86bd62cd8a3d2c0045e1a02c90","modified":1650524289717},{"_id":"public/MultiStyleNST/imgs/video_2.gif","hash":"29aedfc1994a197a8fac488366fe3afc30915e05","modified":1650524289717},{"_id":"public/MultiStyleNST/imgs/video_1.gif","hash":"6cfa2a0d5e66d21f35dd12fb2cde03f490f2efb8","modified":1650524289717},{"_id":"public/Projects/CoinForest.png","hash":"52205868e893bf0b6fb200e1717a7ecf7ba1fd84","modified":1650524289717},{"_id":"public/CoinForest/imgs/CoinForest.png","hash":"52205868e893bf0b6fb200e1717a7ecf7ba1fd84","modified":1650524289717}],"Category":[],"Data":[],"Page":[{"title":"","date":"2020-11-04T03:56:37.000Z","_content":"\n<div>\n\t<h1 style=\"display:inline;\"> CoinForest </h1> \n\t<a href=\"https://github.com/PKhuang-TW/CoinForest\"> [Code] </a> \n</div>\n\n---\n<!-- PROJECT LOGO -->\n<br />\n<p align=\"center\">\n  <a href=\"https://github.com/PKhuang-TW/CoinForest/blob/master/imgs/CoinForest.png\">\n    <img src=\"imgs/CoinForest.png\" alt=\"Poster\" width=\"500\">\n  </a>\n  <h3 align=\"center\">CoinForest</h3>\n  <p align=\"center\">\n    PC Game\n    <br />\n    <a href=\"https://youtu.be/p1SijVLhenE\">View Demo</a>\n    .\n    <a href=\"https://drive.google.com/file/d/1FxQH6BD_9C_lyYJoPSktF8rEyKgS5YFn/view?usp=sharing\">Unity Package</a>\n  </p>\n</p>\n\n\n<!-- ABOUT THE PROJECT -->\n## About The Project\n\nThis is a **PC Game** built by Unity 3D. There are 10 coins in the world, player can either play again or exit after collecting all the coins. <I>Due to the computer performance is not very good, the recorded video is a bit lag, but there is no such phenomenon when playing.</I>\n\n- [x] Terrain and Surroundings\n- [x] Animation (Walking, Jumping)\n- [x] Partical System (Waterfall)\n\n\n### Built With\n\n* [Unity 2017.4.1](https://unity3d.com)","source":"CoinForest/index.md","raw":"---\ntitle: \ndate: 2020-11-04 11:56:37\n---\n\n<div>\n\t<h1 style=\"display:inline;\"> CoinForest </h1> \n\t<a href=\"https://github.com/PKhuang-TW/CoinForest\"> [Code] </a> \n</div>\n\n---\n<!-- PROJECT LOGO -->\n<br />\n<p align=\"center\">\n  <a href=\"https://github.com/PKhuang-TW/CoinForest/blob/master/imgs/CoinForest.png\">\n    <img src=\"imgs/CoinForest.png\" alt=\"Poster\" width=\"500\">\n  </a>\n  <h3 align=\"center\">CoinForest</h3>\n  <p align=\"center\">\n    PC Game\n    <br />\n    <a href=\"https://youtu.be/p1SijVLhenE\">View Demo</a>\n    .\n    <a href=\"https://drive.google.com/file/d/1FxQH6BD_9C_lyYJoPSktF8rEyKgS5YFn/view?usp=sharing\">Unity Package</a>\n  </p>\n</p>\n\n\n<!-- ABOUT THE PROJECT -->\n## About The Project\n\nThis is a **PC Game** built by Unity 3D. There are 10 coins in the world, player can either play again or exit after collecting all the coins. <I>Due to the computer performance is not very good, the recorded video is a bit lag, but there is no such phenomenon when playing.</I>\n\n- [x] Terrain and Surroundings\n- [x] Animation (Walking, Jumping)\n- [x] Partical System (Waterfall)\n\n\n### Built With\n\n* [Unity 2017.4.1](https://unity3d.com)","updated":"2024-01-12T13:45:57.800Z","path":"CoinForest/index.html","_id":"cl28njpb60000vt22b6ju6kyz","comments":1,"layout":"page","content":"<div>\n    <h1 style=\"display:inline;\"> CoinForest </h1> \n    <a href=\"https://github.com/PKhuang-TW/CoinForest\"> [Code] </a> \n</div>\n\n<hr>\n<!-- PROJECT LOGO -->\n<br />\n<p align=\"center\">\n  <a href=\"https://github.com/PKhuang-TW/CoinForest/blob/master/imgs/CoinForest.png\">\n    <img src=\"imgs/CoinForest.png\" alt=\"Poster\" width=\"500\">\n  </a>\n  <h3 align=\"center\">CoinForest</h3>\n  <p align=\"center\">\n    PC Game\n    <br />\n    <a href=\"https://youtu.be/p1SijVLhenE\">View Demo</a>\n    .\n    <a href=\"https://drive.google.com/file/d/1FxQH6BD_9C_lyYJoPSktF8rEyKgS5YFn/view?usp=sharing\">Unity Package</a>\n  </p>\n</p>\n\n\n<!-- ABOUT THE PROJECT -->\n<h2 id=\"About-The-Project\"><a href=\"#About-The-Project\" class=\"headerlink\" title=\"About The Project\"></a>About The Project</h2><p>This is a <strong>PC Game</strong> built by Unity 3D. There are 10 coins in the world, player can either play again or exit after collecting all the coins. <I>Due to the computer performance is not very good, the recorded video is a bit lag, but there is no such phenomenon when playing.</I></p>\n<ul>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> Terrain and Surroundings</li>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> Animation (Walking, Jumping)</li>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> Partical System (Waterfall)</li>\n</ul>\n<h3 id=\"Built-With\"><a href=\"#Built-With\" class=\"headerlink\" title=\"Built With\"></a>Built With</h3><ul>\n<li><a href=\"https://unity3d.com/\">Unity 2017.4.1</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<div>\n    <h1 style=\"display:inline;\"> CoinForest </h1> \n    <a href=\"https://github.com/PKhuang-TW/CoinForest\"> [Code] </a> \n</div>\n\n<hr>\n<!-- PROJECT LOGO -->\n<br />\n<p align=\"center\">\n  <a href=\"https://github.com/PKhuang-TW/CoinForest/blob/master/imgs/CoinForest.png\">\n    <img src=\"imgs/CoinForest.png\" alt=\"Poster\" width=\"500\">\n  </a>\n  <h3 align=\"center\">CoinForest</h3>\n  <p align=\"center\">\n    PC Game\n    <br />\n    <a href=\"https://youtu.be/p1SijVLhenE\">View Demo</a>\n    .\n    <a href=\"https://drive.google.com/file/d/1FxQH6BD_9C_lyYJoPSktF8rEyKgS5YFn/view?usp=sharing\">Unity Package</a>\n  </p>\n</p>\n\n\n<!-- ABOUT THE PROJECT -->\n<h2 id=\"About-The-Project\"><a href=\"#About-The-Project\" class=\"headerlink\" title=\"About The Project\"></a>About The Project</h2><p>This is a <strong>PC Game</strong> built by Unity 3D. There are 10 coins in the world, player can either play again or exit after collecting all the coins. <I>Due to the computer performance is not very good, the recorded video is a bit lag, but there is no such phenomenon when playing.</I></p>\n<ul>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> Terrain and Surroundings</li>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> Animation (Walking, Jumping)</li>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> Partical System (Waterfall)</li>\n</ul>\n<h3 id=\"Built-With\"><a href=\"#Built-With\" class=\"headerlink\" title=\"Built With\"></a>Built With</h3><ul>\n<li><a href=\"https://unity3d.com/\">Unity 2017.4.1</a></li>\n</ul>\n"},{"title":"","date":"2020-11-02T03:20:45.000Z","_content":"\n<div>\n\t<h1 style=\"display:inline;\"> Enchanter </h1> \n\t<a href=\"https://github.com/PKhuang-TW/Enchanter\"> [Code] </a> \n</div>\n\n---\n\n<!-- PROJECT LOGO -->\n<br />\n<p align=\"center\">\n    <img src=\"imgs/poster.png\" alt=\"Poster\" width=\"350\">\n  </a>\n  <h3 align=\"center\">Enchanter</h3>\n  <p align=\"center\">\n    Multiplayer VR Game with Gesture Recognition\n    <br />\n    <a href=\"https://www.youtube.com/watch?v=ky6uT86vLYI&t\">View Demo</a>\n    .\n    <a href=\"https://github.com/PKhuang-TW/Enchanter/tree/master/GameFolder\">Game EXE file</a>\n    .\n    <a href=\"https://github.com/PKhuang-TW/Enchanter/tree/master/UnityPackage\">Unity Package</a>\n  </p>\n</p>\n\n<!-- ABOUT THE PROJECT -->\n## About The Project\n\nThis is a **Multiplayer VR Game** with **Gesture Recognition**. Players fight against each other by casting magic spells drew by their VR controller. Enchanter is developed on HTC VIVE, and [Photon](https://www.photonengine.com/zh-TW/Photon) is used to synchronize the connection. A CNN model is trained to recognize gestures, with five spell symbols and one noise category. We have designed a total of nine skills, each of which has its own characteristics. Players can choose five corresponding spell symbols in the lobby. In addition, in order to prevent dizziness when the player moves in the game, we narrowed the field of view when the user turns his head or moves in the game.\n\n- [x] Terrain and Surroundings\n- [x] Skill Effects\n- [x] Gesture Recognition\n- [x] Support up to 4 players\n\n<img src = \"./imgs/ScreenShot.png\" class=\"projectDetailImg\">\n\n\n### Built With\n\n* [Unity 2017.4.1](https://unity3d.com)\n* [Python 3.6](https://www.python.org/downloads/release/python-360/)\n* [CUDA 9.0](https://developer.nvidia.com/cuda-90-download-archive)\n* [Pytorch](https://pytorch.org) - Has to mactch the version of Python and CUDA.\n* [Photon](https://www.photonengine.com/zh-TW/Photon)\n* [Final IK](https://assetstore.unity.com/packages/tools/animation/final-ik-14290?gclid=Cj0KCQjwufn8BRCwARIsAKzP6967iMRUnoCr9pBa3LgBCQehINS8GzqnlY0Hh_iXk-BvSXZcUF8JLt4aAlIDEALw_wcB)\n* [Photoshop](https://www.adobe.com/tw/products/photoshop.html)\n\n### Procedure\n<img src = \"./imgs/procedure.png\" class=\"projectDetailImg\">\n\n\n<!-- GETTING STARTED -->\n## Getting Started\n\nTo start playing Enchanter, Python 3.6 and CUDA 9.0 has to be installed. Pytorch version has to match versions of Python and CUDA. On the other hand, Enchanter operates a local python server at background, so there are several python packages necessary.\n\n### Installation\n\n1. **Pytorch** - If you can't find the installation method of pytorch:\n```sh\n./NecessaryPackage/Pytorch_Python36_CUDA9.bat\n```\n2. **Python Packages** - There are several packages like: sockets, tqdm.... have to be installed:\n```sh\n./NecessaryPackage/PythonPackage.bat\n```\n3. Download whole Pack of \"Enchanter\" and exucute \"Enchanter.exe\" to play the game.\n","source":"Enchanter/index.md","raw":"---\ntitle: \ndate: 2020-11-02 11:20:45\n---\n\n<div>\n\t<h1 style=\"display:inline;\"> Enchanter </h1> \n\t<a href=\"https://github.com/PKhuang-TW/Enchanter\"> [Code] </a> \n</div>\n\n---\n\n<!-- PROJECT LOGO -->\n<br />\n<p align=\"center\">\n    <img src=\"imgs/poster.png\" alt=\"Poster\" width=\"350\">\n  </a>\n  <h3 align=\"center\">Enchanter</h3>\n  <p align=\"center\">\n    Multiplayer VR Game with Gesture Recognition\n    <br />\n    <a href=\"https://www.youtube.com/watch?v=ky6uT86vLYI&t\">View Demo</a>\n    .\n    <a href=\"https://github.com/PKhuang-TW/Enchanter/tree/master/GameFolder\">Game EXE file</a>\n    .\n    <a href=\"https://github.com/PKhuang-TW/Enchanter/tree/master/UnityPackage\">Unity Package</a>\n  </p>\n</p>\n\n<!-- ABOUT THE PROJECT -->\n## About The Project\n\nThis is a **Multiplayer VR Game** with **Gesture Recognition**. Players fight against each other by casting magic spells drew by their VR controller. Enchanter is developed on HTC VIVE, and [Photon](https://www.photonengine.com/zh-TW/Photon) is used to synchronize the connection. A CNN model is trained to recognize gestures, with five spell symbols and one noise category. We have designed a total of nine skills, each of which has its own characteristics. Players can choose five corresponding spell symbols in the lobby. In addition, in order to prevent dizziness when the player moves in the game, we narrowed the field of view when the user turns his head or moves in the game.\n\n- [x] Terrain and Surroundings\n- [x] Skill Effects\n- [x] Gesture Recognition\n- [x] Support up to 4 players\n\n<img src = \"./imgs/ScreenShot.png\" class=\"projectDetailImg\">\n\n\n### Built With\n\n* [Unity 2017.4.1](https://unity3d.com)\n* [Python 3.6](https://www.python.org/downloads/release/python-360/)\n* [CUDA 9.0](https://developer.nvidia.com/cuda-90-download-archive)\n* [Pytorch](https://pytorch.org) - Has to mactch the version of Python and CUDA.\n* [Photon](https://www.photonengine.com/zh-TW/Photon)\n* [Final IK](https://assetstore.unity.com/packages/tools/animation/final-ik-14290?gclid=Cj0KCQjwufn8BRCwARIsAKzP6967iMRUnoCr9pBa3LgBCQehINS8GzqnlY0Hh_iXk-BvSXZcUF8JLt4aAlIDEALw_wcB)\n* [Photoshop](https://www.adobe.com/tw/products/photoshop.html)\n\n### Procedure\n<img src = \"./imgs/procedure.png\" class=\"projectDetailImg\">\n\n\n<!-- GETTING STARTED -->\n## Getting Started\n\nTo start playing Enchanter, Python 3.6 and CUDA 9.0 has to be installed. Pytorch version has to match versions of Python and CUDA. On the other hand, Enchanter operates a local python server at background, so there are several python packages necessary.\n\n### Installation\n\n1. **Pytorch** - If you can't find the installation method of pytorch:\n```sh\n./NecessaryPackage/Pytorch_Python36_CUDA9.bat\n```\n2. **Python Packages** - There are several packages like: sockets, tqdm.... have to be installed:\n```sh\n./NecessaryPackage/PythonPackage.bat\n```\n3. Download whole Pack of \"Enchanter\" and exucute \"Enchanter.exe\" to play the game.\n","updated":"2024-01-12T13:45:57.818Z","path":"Enchanter/index.html","_id":"cl28njpba0001vt220idxgmqc","comments":1,"layout":"page","content":"<div>\n    <h1 style=\"display:inline;\"> Enchanter </h1> \n    <a href=\"https://github.com/PKhuang-TW/Enchanter\"> [Code] </a> \n</div>\n\n<hr>\n<!-- PROJECT LOGO -->\n<br />\n<p align=\"center\">\n    <img src=\"imgs/poster.png\" alt=\"Poster\" width=\"350\">\n  </a>\n  <h3 align=\"center\">Enchanter</h3>\n  <p align=\"center\">\n    Multiplayer VR Game with Gesture Recognition\n    <br />\n    <a href=\"https://www.youtube.com/watch?v=ky6uT86vLYI&t\">View Demo</a>\n    .\n    <a href=\"https://github.com/PKhuang-TW/Enchanter/tree/master/GameFolder\">Game EXE file</a>\n    .\n    <a href=\"https://github.com/PKhuang-TW/Enchanter/tree/master/UnityPackage\">Unity Package</a>\n  </p>\n</p>\n\n<!-- ABOUT THE PROJECT -->\n<h2 id=\"About-The-Project\"><a href=\"#About-The-Project\" class=\"headerlink\" title=\"About The Project\"></a>About The Project</h2><p>This is a <strong>Multiplayer VR Game</strong> with <strong>Gesture Recognition</strong>. Players fight against each other by casting magic spells drew by their VR controller. Enchanter is developed on HTC VIVE, and <a href=\"https://www.photonengine.com/zh-TW/Photon\">Photon</a> is used to synchronize the connection. A CNN model is trained to recognize gestures, with five spell symbols and one noise category. We have designed a total of nine skills, each of which has its own characteristics. Players can choose five corresponding spell symbols in the lobby. In addition, in order to prevent dizziness when the player moves in the game, we narrowed the field of view when the user turns his head or moves in the game.</p>\n<ul>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> Terrain and Surroundings</li>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> Skill Effects</li>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> Gesture Recognition</li>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> Support up to 4 players</li>\n</ul>\n<img src = \"./imgs/ScreenShot.png\" class=\"projectDetailImg\">\n\n\n<h3 id=\"Built-With\"><a href=\"#Built-With\" class=\"headerlink\" title=\"Built With\"></a>Built With</h3><ul>\n<li><a href=\"https://unity3d.com/\">Unity 2017.4.1</a></li>\n<li><a href=\"https://www.python.org/downloads/release/python-360/\">Python 3.6</a></li>\n<li><a href=\"https://developer.nvidia.com/cuda-90-download-archive\">CUDA 9.0</a></li>\n<li><a href=\"https://pytorch.org/\">Pytorch</a> - Has to mactch the version of Python and CUDA.</li>\n<li><a href=\"https://www.photonengine.com/zh-TW/Photon\">Photon</a></li>\n<li><a href=\"https://assetstore.unity.com/packages/tools/animation/final-ik-14290?gclid=Cj0KCQjwufn8BRCwARIsAKzP6967iMRUnoCr9pBa3LgBCQehINS8GzqnlY0Hh_iXk-BvSXZcUF8JLt4aAlIDEALw_wcB\">Final IK</a></li>\n<li><a href=\"https://www.adobe.com/tw/products/photoshop.html\">Photoshop</a></li>\n</ul>\n<h3 id=\"Procedure\"><a href=\"#Procedure\" class=\"headerlink\" title=\"Procedure\"></a>Procedure</h3><img src = \"./imgs/procedure.png\" class=\"projectDetailImg\">\n\n\n<!-- GETTING STARTED -->\n<h2 id=\"Getting-Started\"><a href=\"#Getting-Started\" class=\"headerlink\" title=\"Getting Started\"></a>Getting Started</h2><p>To start playing Enchanter, Python 3.6 and CUDA 9.0 has to be installed. Pytorch version has to match versions of Python and CUDA. On the other hand, Enchanter operates a local python server at background, so there are several python packages necessary.</p>\n<h3 id=\"Installation\"><a href=\"#Installation\" class=\"headerlink\" title=\"Installation\"></a>Installation</h3><ol>\n<li><strong>Pytorch</strong> - If you can’t find the installation method of pytorch:<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./NecessaryPackage/Pytorch_Python36_CUDA9.bat</span><br></pre></td></tr></table></figure></li>\n<li><strong>Python Packages</strong> - There are several packages like: sockets, tqdm…. have to be installed:<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./NecessaryPackage/PythonPackage.bat</span><br></pre></td></tr></table></figure></li>\n<li>Download whole Pack of “Enchanter” and exucute “Enchanter.exe” to play the game.</li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<div>\n    <h1 style=\"display:inline;\"> Enchanter </h1> \n    <a href=\"https://github.com/PKhuang-TW/Enchanter\"> [Code] </a> \n</div>\n\n<hr>\n<!-- PROJECT LOGO -->\n<br />\n<p align=\"center\">\n    <img src=\"imgs/poster.png\" alt=\"Poster\" width=\"350\">\n  </a>\n  <h3 align=\"center\">Enchanter</h3>\n  <p align=\"center\">\n    Multiplayer VR Game with Gesture Recognition\n    <br />\n    <a href=\"https://www.youtube.com/watch?v=ky6uT86vLYI&t\">View Demo</a>\n    .\n    <a href=\"https://github.com/PKhuang-TW/Enchanter/tree/master/GameFolder\">Game EXE file</a>\n    .\n    <a href=\"https://github.com/PKhuang-TW/Enchanter/tree/master/UnityPackage\">Unity Package</a>\n  </p>\n</p>\n\n<!-- ABOUT THE PROJECT -->\n<h2 id=\"About-The-Project\"><a href=\"#About-The-Project\" class=\"headerlink\" title=\"About The Project\"></a>About The Project</h2><p>This is a <strong>Multiplayer VR Game</strong> with <strong>Gesture Recognition</strong>. Players fight against each other by casting magic spells drew by their VR controller. Enchanter is developed on HTC VIVE, and <a href=\"https://www.photonengine.com/zh-TW/Photon\">Photon</a> is used to synchronize the connection. A CNN model is trained to recognize gestures, with five spell symbols and one noise category. We have designed a total of nine skills, each of which has its own characteristics. Players can choose five corresponding spell symbols in the lobby. In addition, in order to prevent dizziness when the player moves in the game, we narrowed the field of view when the user turns his head or moves in the game.</p>\n<ul>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> Terrain and Surroundings</li>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> Skill Effects</li>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> Gesture Recognition</li>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> Support up to 4 players</li>\n</ul>\n<img src = \"./imgs/ScreenShot.png\" class=\"projectDetailImg\">\n\n\n<h3 id=\"Built-With\"><a href=\"#Built-With\" class=\"headerlink\" title=\"Built With\"></a>Built With</h3><ul>\n<li><a href=\"https://unity3d.com/\">Unity 2017.4.1</a></li>\n<li><a href=\"https://www.python.org/downloads/release/python-360/\">Python 3.6</a></li>\n<li><a href=\"https://developer.nvidia.com/cuda-90-download-archive\">CUDA 9.0</a></li>\n<li><a href=\"https://pytorch.org/\">Pytorch</a> - Has to mactch the version of Python and CUDA.</li>\n<li><a href=\"https://www.photonengine.com/zh-TW/Photon\">Photon</a></li>\n<li><a href=\"https://assetstore.unity.com/packages/tools/animation/final-ik-14290?gclid=Cj0KCQjwufn8BRCwARIsAKzP6967iMRUnoCr9pBa3LgBCQehINS8GzqnlY0Hh_iXk-BvSXZcUF8JLt4aAlIDEALw_wcB\">Final IK</a></li>\n<li><a href=\"https://www.adobe.com/tw/products/photoshop.html\">Photoshop</a></li>\n</ul>\n<h3 id=\"Procedure\"><a href=\"#Procedure\" class=\"headerlink\" title=\"Procedure\"></a>Procedure</h3><img src = \"./imgs/procedure.png\" class=\"projectDetailImg\">\n\n\n<!-- GETTING STARTED -->\n<h2 id=\"Getting-Started\"><a href=\"#Getting-Started\" class=\"headerlink\" title=\"Getting Started\"></a>Getting Started</h2><p>To start playing Enchanter, Python 3.6 and CUDA 9.0 has to be installed. Pytorch version has to match versions of Python and CUDA. On the other hand, Enchanter operates a local python server at background, so there are several python packages necessary.</p>\n<h3 id=\"Installation\"><a href=\"#Installation\" class=\"headerlink\" title=\"Installation\"></a>Installation</h3><ol>\n<li><strong>Pytorch</strong> - If you can’t find the installation method of pytorch:<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./NecessaryPackage/Pytorch_Python36_CUDA9.bat</span><br></pre></td></tr></table></figure></li>\n<li><strong>Python Packages</strong> - There are several packages like: sockets, tqdm…. have to be installed:<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./NecessaryPackage/PythonPackage.bat</span><br></pre></td></tr></table></figure></li>\n<li>Download whole Pack of “Enchanter” and exucute “Enchanter.exe” to play the game.</li>\n</ol>\n"},{"title":"","date":"2020-11-02T03:04:52.000Z","_content":"\n<div>\n\t<h1 style=\"display:inline;\"> Multi-Style Semantic Style Transfer </h1> \n\t<a href=\"https://github.com/PKhuang-TW/MultiStyle-Semantic-Style-Transfer\"> [Code] </a> \n</div>\n\n---\n\nThis project is aimed to transfer different semantic objects in one image into different styles. We use pretrained semantic segmentation model (DeepLab-V3) to get the foregound and backgound region, and apply style transfer on different style for each region. In addition to style loss and content loss in traditional neural style transfer, we futher add style-blending loss and total variance loss to make the result more harmony when blending very different style. Also, we provide custom control of blending effect. \n\n## Model Architecture\n<img src = \"./imgs/model_architecture.png\" class=\"projectDetailImg\">\nGiven one image I<sub>src</sub> and two target style images I<sub>s1</sub> and I<sub>s2</sub>, we want to transfer different semantic objects into different style accrodingly. We first produced two intermediated result image I<sub>i1</sub> and I<sub>i2</sub>, and compute the style loss between (I<sub>s1</sub>, I<sub>i1</sub>) and (I<sub>s2</sub>, I<sub>i2</sub>). The we merge these two intermediated images into final result image I<sub>result</sub> by semantic map predicted by DeepLab-V3 image. Finally compute the content loss between (I<sub>src</sub>, I<sub>result</sub>). Further more, to make the resulting image more harmony while blending different styles and prevent weird boundary after merging two intermediated images, we also compute the style-blending loss which is weighted style loss between (I<sub>s1</sub>, I<sub>i2</sub>) and (I<sub>s2</sub>, I<sub>i1</sub>), and smooth loss which is total variance of I<sub>result</sub>. The entire loss function can be written as follow:<br/>\nL = &lambda;<sub>1</sub>L<sub>style</sub> + &lambda;<sub>2</sub>L<sub>blend</sub> + &lambda;<sub>3</sub>L<sub>content</sub> + &lambda;<sub>4</sub>L<sub>Smooth</sub>\n&nbsp;\n\n## Result \n### Compare with naive approach\n<img src = \"./imgs/compare.png\" class=\"projectDetailImg\">\nTo validate the effectiveness of additional loss function, we compare the result from removing both blending and smooth loss (left figure), the result from removing smooth loss (mid figure) and the result from using all loss function mentioned above (right figure). From the result we can observe that the naive method will result in weird boundary between different semantic objects. After adding the blending loss, this artifact would improve a lot, and the result of boundary is most clean if all loss function is applied. However, after adding the smooth loss, the resulting image will loss some detail of style (e.g., little spot and stripe). We consider it is an tradeoff between less artifact at boundary and more detail in style, and the effect can be control through adjust the weight of smooth loss.\n<p>\n\n### Style Blending Ratio\n<img src = \"./imgs/blending.png\" class=\"projectDetailImg\">\nFurthermore, we observe that using naive method sometimes cause the resulting image to become very disharmonious if the two target style is very different (the first figure). After adding the style blending loss, the resulting will become much harmonious (the last figure). However, when the weight of blending loss become too large, it become hard to distinguish different style in different semantic object. So again, we consider it is a tradeoff between making the resulting image more distinguishable to different style and more harmonious.\n<p>\n\n### Sample Result\n<img src=\"./imgs/result_1.png\" width=\"40%\"> <img src=\"./imgs/result_2.png\" width=\"40%\">\n<p>\n\n### Video Style Transfer\n<img src = \"./imgs/model_video.png\" class=\"projectDetailImg\"> \nTraditional neural style transfer use <b>On-line Image Optimization</b> approach, but it could take long time if we want to transfer many image (In our environment, optimize an image take a few minutes). To transfer a video that contain hundred of even thousand of frames, we first use <b>Off-line Model optimization</b> approach to train a transfer model, the for each frame in the video, we can feed it into model and get the resulting image in a few second, whcih make transfer style of video become more practicable. <br/>\n<img src=\"./imgs/video_1.gif\" width=\"40%\"> <img src=\"./imgs/video_2.gif\" width=\"40%\"> <br/>\n\n","source":"MultiStyleNST/index.md","raw":"---\ntitle: \ndate: 2020-11-02 11:04:52\n---\n\n<div>\n\t<h1 style=\"display:inline;\"> Multi-Style Semantic Style Transfer </h1> \n\t<a href=\"https://github.com/PKhuang-TW/MultiStyle-Semantic-Style-Transfer\"> [Code] </a> \n</div>\n\n---\n\nThis project is aimed to transfer different semantic objects in one image into different styles. We use pretrained semantic segmentation model (DeepLab-V3) to get the foregound and backgound region, and apply style transfer on different style for each region. In addition to style loss and content loss in traditional neural style transfer, we futher add style-blending loss and total variance loss to make the result more harmony when blending very different style. Also, we provide custom control of blending effect. \n\n## Model Architecture\n<img src = \"./imgs/model_architecture.png\" class=\"projectDetailImg\">\nGiven one image I<sub>src</sub> and two target style images I<sub>s1</sub> and I<sub>s2</sub>, we want to transfer different semantic objects into different style accrodingly. We first produced two intermediated result image I<sub>i1</sub> and I<sub>i2</sub>, and compute the style loss between (I<sub>s1</sub>, I<sub>i1</sub>) and (I<sub>s2</sub>, I<sub>i2</sub>). The we merge these two intermediated images into final result image I<sub>result</sub> by semantic map predicted by DeepLab-V3 image. Finally compute the content loss between (I<sub>src</sub>, I<sub>result</sub>). Further more, to make the resulting image more harmony while blending different styles and prevent weird boundary after merging two intermediated images, we also compute the style-blending loss which is weighted style loss between (I<sub>s1</sub>, I<sub>i2</sub>) and (I<sub>s2</sub>, I<sub>i1</sub>), and smooth loss which is total variance of I<sub>result</sub>. The entire loss function can be written as follow:<br/>\nL = &lambda;<sub>1</sub>L<sub>style</sub> + &lambda;<sub>2</sub>L<sub>blend</sub> + &lambda;<sub>3</sub>L<sub>content</sub> + &lambda;<sub>4</sub>L<sub>Smooth</sub>\n&nbsp;\n\n## Result \n### Compare with naive approach\n<img src = \"./imgs/compare.png\" class=\"projectDetailImg\">\nTo validate the effectiveness of additional loss function, we compare the result from removing both blending and smooth loss (left figure), the result from removing smooth loss (mid figure) and the result from using all loss function mentioned above (right figure). From the result we can observe that the naive method will result in weird boundary between different semantic objects. After adding the blending loss, this artifact would improve a lot, and the result of boundary is most clean if all loss function is applied. However, after adding the smooth loss, the resulting image will loss some detail of style (e.g., little spot and stripe). We consider it is an tradeoff between less artifact at boundary and more detail in style, and the effect can be control through adjust the weight of smooth loss.\n<p>\n\n### Style Blending Ratio\n<img src = \"./imgs/blending.png\" class=\"projectDetailImg\">\nFurthermore, we observe that using naive method sometimes cause the resulting image to become very disharmonious if the two target style is very different (the first figure). After adding the style blending loss, the resulting will become much harmonious (the last figure). However, when the weight of blending loss become too large, it become hard to distinguish different style in different semantic object. So again, we consider it is a tradeoff between making the resulting image more distinguishable to different style and more harmonious.\n<p>\n\n### Sample Result\n<img src=\"./imgs/result_1.png\" width=\"40%\"> <img src=\"./imgs/result_2.png\" width=\"40%\">\n<p>\n\n### Video Style Transfer\n<img src = \"./imgs/model_video.png\" class=\"projectDetailImg\"> \nTraditional neural style transfer use <b>On-line Image Optimization</b> approach, but it could take long time if we want to transfer many image (In our environment, optimize an image take a few minutes). To transfer a video that contain hundred of even thousand of frames, we first use <b>Off-line Model optimization</b> approach to train a transfer model, the for each frame in the video, we can feed it into model and get the resulting image in a few second, whcih make transfer style of video become more practicable. <br/>\n<img src=\"./imgs/video_1.gif\" width=\"40%\"> <img src=\"./imgs/video_2.gif\" width=\"40%\"> <br/>\n\n","updated":"2024-01-12T13:45:57.916Z","path":"MultiStyleNST/index.html","_id":"cl28njpba0002vt2211wcfang","comments":1,"layout":"page","content":"<div>\n    <h1 style=\"display:inline;\"> Multi-Style Semantic Style Transfer </h1> \n    <a href=\"https://github.com/PKhuang-TW/MultiStyle-Semantic-Style-Transfer\"> [Code] </a> \n</div>\n\n<hr>\n<p>This project is aimed to transfer different semantic objects in one image into different styles. We use pretrained semantic segmentation model (DeepLab-V3) to get the foregound and backgound region, and apply style transfer on different style for each region. In addition to style loss and content loss in traditional neural style transfer, we futher add style-blending loss and total variance loss to make the result more harmony when blending very different style. Also, we provide custom control of blending effect. </p>\n<h2 id=\"Model-Architecture\"><a href=\"#Model-Architecture\" class=\"headerlink\" title=\"Model Architecture\"></a>Model Architecture</h2><img src = \"./imgs/model_architecture.png\" class=\"projectDetailImg\">\nGiven one image I<sub>src</sub> and two target style images I<sub>s1</sub> and I<sub>s2</sub>, we want to transfer different semantic objects into different style accrodingly. We first produced two intermediated result image I<sub>i1</sub> and I<sub>i2</sub>, and compute the style loss between (I<sub>s1</sub>, I<sub>i1</sub>) and (I<sub>s2</sub>, I<sub>i2</sub>). The we merge these two intermediated images into final result image I<sub>result</sub> by semantic map predicted by DeepLab-V3 image. Finally compute the content loss between (I<sub>src</sub>, I<sub>result</sub>). Further more, to make the resulting image more harmony while blending different styles and prevent weird boundary after merging two intermediated images, we also compute the style-blending loss which is weighted style loss between (I<sub>s1</sub>, I<sub>i2</sub>) and (I<sub>s2</sub>, I<sub>i1</sub>), and smooth loss which is total variance of I<sub>result</sub>. The entire loss function can be written as follow:<br/>\nL = &lambda;<sub>1</sub>L<sub>style</sub> + &lambda;<sub>2</sub>L<sub>blend</sub> + &lambda;<sub>3</sub>L<sub>content</sub> + &lambda;<sub>4</sub>L<sub>Smooth</sub>\n&nbsp;\n\n<h2 id=\"Result\"><a href=\"#Result\" class=\"headerlink\" title=\"Result\"></a>Result</h2><h3 id=\"Compare-with-naive-approach\"><a href=\"#Compare-with-naive-approach\" class=\"headerlink\" title=\"Compare with naive approach\"></a>Compare with naive approach</h3><img src = \"./imgs/compare.png\" class=\"projectDetailImg\">\nTo validate the effectiveness of additional loss function, we compare the result from removing both blending and smooth loss (left figure), the result from removing smooth loss (mid figure) and the result from using all loss function mentioned above (right figure). From the result we can observe that the naive method will result in weird boundary between different semantic objects. After adding the blending loss, this artifact would improve a lot, and the result of boundary is most clean if all loss function is applied. However, after adding the smooth loss, the resulting image will loss some detail of style (e.g., little spot and stripe). We consider it is an tradeoff between less artifact at boundary and more detail in style, and the effect can be control through adjust the weight of smooth loss.\n<p>\n\n<h3 id=\"Style-Blending-Ratio\"><a href=\"#Style-Blending-Ratio\" class=\"headerlink\" title=\"Style Blending Ratio\"></a>Style Blending Ratio</h3><img src = \"./imgs/blending.png\" class=\"projectDetailImg\">\nFurthermore, we observe that using naive method sometimes cause the resulting image to become very disharmonious if the two target style is very different (the first figure). After adding the style blending loss, the resulting will become much harmonious (the last figure). However, when the weight of blending loss become too large, it become hard to distinguish different style in different semantic object. So again, we consider it is a tradeoff between making the resulting image more distinguishable to different style and more harmonious.\n<p>\n\n<h3 id=\"Sample-Result\"><a href=\"#Sample-Result\" class=\"headerlink\" title=\"Sample Result\"></a>Sample Result</h3><p><img src=\"./imgs/result_1.png\" width=\"40%\"> <img src=\"./imgs/result_2.png\" width=\"40%\"></p>\n<p>\n\n<h3 id=\"Video-Style-Transfer\"><a href=\"#Video-Style-Transfer\" class=\"headerlink\" title=\"Video Style Transfer\"></a>Video Style Transfer</h3><img src = \"./imgs/model_video.png\" class=\"projectDetailImg\"> \nTraditional neural style transfer use <b>On-line Image Optimization</b> approach, but it could take long time if we want to transfer many image (In our environment, optimize an image take a few minutes). To transfer a video that contain hundred of even thousand of frames, we first use <b>Off-line Model optimization</b> approach to train a transfer model, the for each frame in the video, we can feed it into model and get the resulting image in a few second, whcih make transfer style of video become more practicable. <br/>\n<img src=\"./imgs/video_1.gif\" width=\"40%\"> <img src=\"./imgs/video_2.gif\" width=\"40%\"> <br/>\n\n","site":{"data":{}},"excerpt":"","more":"<div>\n    <h1 style=\"display:inline;\"> Multi-Style Semantic Style Transfer </h1> \n    <a href=\"https://github.com/PKhuang-TW/MultiStyle-Semantic-Style-Transfer\"> [Code] </a> \n</div>\n\n<hr>\n<p>This project is aimed to transfer different semantic objects in one image into different styles. We use pretrained semantic segmentation model (DeepLab-V3) to get the foregound and backgound region, and apply style transfer on different style for each region. In addition to style loss and content loss in traditional neural style transfer, we futher add style-blending loss and total variance loss to make the result more harmony when blending very different style. Also, we provide custom control of blending effect. </p>\n<h2 id=\"Model-Architecture\"><a href=\"#Model-Architecture\" class=\"headerlink\" title=\"Model Architecture\"></a>Model Architecture</h2><img src = \"./imgs/model_architecture.png\" class=\"projectDetailImg\">\nGiven one image I<sub>src</sub> and two target style images I<sub>s1</sub> and I<sub>s2</sub>, we want to transfer different semantic objects into different style accrodingly. We first produced two intermediated result image I<sub>i1</sub> and I<sub>i2</sub>, and compute the style loss between (I<sub>s1</sub>, I<sub>i1</sub>) and (I<sub>s2</sub>, I<sub>i2</sub>). The we merge these two intermediated images into final result image I<sub>result</sub> by semantic map predicted by DeepLab-V3 image. Finally compute the content loss between (I<sub>src</sub>, I<sub>result</sub>). Further more, to make the resulting image more harmony while blending different styles and prevent weird boundary after merging two intermediated images, we also compute the style-blending loss which is weighted style loss between (I<sub>s1</sub>, I<sub>i2</sub>) and (I<sub>s2</sub>, I<sub>i1</sub>), and smooth loss which is total variance of I<sub>result</sub>. The entire loss function can be written as follow:<br/>\nL = &lambda;<sub>1</sub>L<sub>style</sub> + &lambda;<sub>2</sub>L<sub>blend</sub> + &lambda;<sub>3</sub>L<sub>content</sub> + &lambda;<sub>4</sub>L<sub>Smooth</sub>\n&nbsp;\n\n<h2 id=\"Result\"><a href=\"#Result\" class=\"headerlink\" title=\"Result\"></a>Result</h2><h3 id=\"Compare-with-naive-approach\"><a href=\"#Compare-with-naive-approach\" class=\"headerlink\" title=\"Compare with naive approach\"></a>Compare with naive approach</h3><img src = \"./imgs/compare.png\" class=\"projectDetailImg\">\nTo validate the effectiveness of additional loss function, we compare the result from removing both blending and smooth loss (left figure), the result from removing smooth loss (mid figure) and the result from using all loss function mentioned above (right figure). From the result we can observe that the naive method will result in weird boundary between different semantic objects. After adding the blending loss, this artifact would improve a lot, and the result of boundary is most clean if all loss function is applied. However, after adding the smooth loss, the resulting image will loss some detail of style (e.g., little spot and stripe). We consider it is an tradeoff between less artifact at boundary and more detail in style, and the effect can be control through adjust the weight of smooth loss.\n<p>\n\n<h3 id=\"Style-Blending-Ratio\"><a href=\"#Style-Blending-Ratio\" class=\"headerlink\" title=\"Style Blending Ratio\"></a>Style Blending Ratio</h3><img src = \"./imgs/blending.png\" class=\"projectDetailImg\">\nFurthermore, we observe that using naive method sometimes cause the resulting image to become very disharmonious if the two target style is very different (the first figure). After adding the style blending loss, the resulting will become much harmonious (the last figure). However, when the weight of blending loss become too large, it become hard to distinguish different style in different semantic object. So again, we consider it is a tradeoff between making the resulting image more distinguishable to different style and more harmonious.\n<p>\n\n<h3 id=\"Sample-Result\"><a href=\"#Sample-Result\" class=\"headerlink\" title=\"Sample Result\"></a>Sample Result</h3><p><img src=\"./imgs/result_1.png\" width=\"40%\"> <img src=\"./imgs/result_2.png\" width=\"40%\"></p>\n<p>\n\n<h3 id=\"Video-Style-Transfer\"><a href=\"#Video-Style-Transfer\" class=\"headerlink\" title=\"Video Style Transfer\"></a>Video Style Transfer</h3><img src = \"./imgs/model_video.png\" class=\"projectDetailImg\"> \nTraditional neural style transfer use <b>On-line Image Optimization</b> approach, but it could take long time if we want to transfer many image (In our environment, optimize an image take a few minutes). To transfer a video that contain hundred of even thousand of frames, we first use <b>Off-line Model optimization</b> approach to train a transfer model, the for each frame in the video, we can feed it into model and get the resulting image in a few second, whcih make transfer style of video become more practicable. <br/>\n<img src=\"./imgs/video_1.gif\" width=\"40%\"> <img src=\"./imgs/video_2.gif\" width=\"40%\"> <br/>\n\n"},{"title":"","date":"2020-11-04T03:56:37.000Z","_content":"\n<div>\n\t<h1 style=\"display:inline;\"> HappyDancing </h1> \n\t<a href=\"https://github.com/PKhuang-TW/HappyDancing\"> [Code] </a> \n</div>\n\n---\n\n<!-- PROJECT LOGO -->\n<br />\n<p align=\"center\">\n  <a href=\"https://github.com/PKhuang-TW/HappyDancing/blob/master/imgs/HappyDancing.png\">\n    <img src=\"imgs/HappyDancing.png\" width=\"800\">\n  </a>\n  <h3 align=\"center\">HappyDancing</h3>\n  <p align=\"center\">\n    AR Characters Interaction\n    <br />\n    <a href=\"https://youtu.be/tKGlHF4obC0\">View Demo</a>\n    .\n    <a href=\"https://drive.google.com/file/d/1lMykZDWJjKQO58NvJxWE2bWv6ck8fyLI/view?usp=sharing\">Unity Package</a>\n  </p>\n</p>\n\n\n<!-- ABOUT THE PROJECT -->\n## About The Project\n\nTwo AR character are assigned to two QR codes in this project, and will dance to each other while they meet in AR world. Dancing animation and music will begin when they start dancing.\n\n- [x] Animation\n- [x] Particle System\n- [x] AR tags\n\n### Built With\n\n* [Unity 2017.4.1](https://unity3d.com)\n* [Vuforia](https://developer.vuforia.com)\n* [Mixamo](https://www.mixamo.com/)","source":"HappyDancing/index.md","raw":"---\ntitle: \ndate: 2020-11-04 11:56:37\n---\n\n<div>\n\t<h1 style=\"display:inline;\"> HappyDancing </h1> \n\t<a href=\"https://github.com/PKhuang-TW/HappyDancing\"> [Code] </a> \n</div>\n\n---\n\n<!-- PROJECT LOGO -->\n<br />\n<p align=\"center\">\n  <a href=\"https://github.com/PKhuang-TW/HappyDancing/blob/master/imgs/HappyDancing.png\">\n    <img src=\"imgs/HappyDancing.png\" width=\"800\">\n  </a>\n  <h3 align=\"center\">HappyDancing</h3>\n  <p align=\"center\">\n    AR Characters Interaction\n    <br />\n    <a href=\"https://youtu.be/tKGlHF4obC0\">View Demo</a>\n    .\n    <a href=\"https://drive.google.com/file/d/1lMykZDWJjKQO58NvJxWE2bWv6ck8fyLI/view?usp=sharing\">Unity Package</a>\n  </p>\n</p>\n\n\n<!-- ABOUT THE PROJECT -->\n## About The Project\n\nTwo AR character are assigned to two QR codes in this project, and will dance to each other while they meet in AR world. Dancing animation and music will begin when they start dancing.\n\n- [x] Animation\n- [x] Particle System\n- [x] AR tags\n\n### Built With\n\n* [Unity 2017.4.1](https://unity3d.com)\n* [Vuforia](https://developer.vuforia.com)\n* [Mixamo](https://www.mixamo.com/)","updated":"2024-01-12T13:45:57.823Z","path":"HappyDancing/index.html","_id":"cl28njpbb0003vt22ffuy7vf3","comments":1,"layout":"page","content":"<div>\n    <h1 style=\"display:inline;\"> HappyDancing </h1> \n    <a href=\"https://github.com/PKhuang-TW/HappyDancing\"> [Code] </a> \n</div>\n\n<hr>\n<!-- PROJECT LOGO -->\n<br />\n<p align=\"center\">\n  <a href=\"https://github.com/PKhuang-TW/HappyDancing/blob/master/imgs/HappyDancing.png\">\n    <img src=\"imgs/HappyDancing.png\" width=\"800\">\n  </a>\n  <h3 align=\"center\">HappyDancing</h3>\n  <p align=\"center\">\n    AR Characters Interaction\n    <br />\n    <a href=\"https://youtu.be/tKGlHF4obC0\">View Demo</a>\n    .\n    <a href=\"https://drive.google.com/file/d/1lMykZDWJjKQO58NvJxWE2bWv6ck8fyLI/view?usp=sharing\">Unity Package</a>\n  </p>\n</p>\n\n\n<!-- ABOUT THE PROJECT -->\n<h2 id=\"About-The-Project\"><a href=\"#About-The-Project\" class=\"headerlink\" title=\"About The Project\"></a>About The Project</h2><p>Two AR character are assigned to two QR codes in this project, and will dance to each other while they meet in AR world. Dancing animation and music will begin when they start dancing.</p>\n<ul>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> Animation</li>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> Particle System</li>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> AR tags</li>\n</ul>\n<h3 id=\"Built-With\"><a href=\"#Built-With\" class=\"headerlink\" title=\"Built With\"></a>Built With</h3><ul>\n<li><a href=\"https://unity3d.com/\">Unity 2017.4.1</a></li>\n<li><a href=\"https://developer.vuforia.com/\">Vuforia</a></li>\n<li><a href=\"https://www.mixamo.com/\">Mixamo</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<div>\n    <h1 style=\"display:inline;\"> HappyDancing </h1> \n    <a href=\"https://github.com/PKhuang-TW/HappyDancing\"> [Code] </a> \n</div>\n\n<hr>\n<!-- PROJECT LOGO -->\n<br />\n<p align=\"center\">\n  <a href=\"https://github.com/PKhuang-TW/HappyDancing/blob/master/imgs/HappyDancing.png\">\n    <img src=\"imgs/HappyDancing.png\" width=\"800\">\n  </a>\n  <h3 align=\"center\">HappyDancing</h3>\n  <p align=\"center\">\n    AR Characters Interaction\n    <br />\n    <a href=\"https://youtu.be/tKGlHF4obC0\">View Demo</a>\n    .\n    <a href=\"https://drive.google.com/file/d/1lMykZDWJjKQO58NvJxWE2bWv6ck8fyLI/view?usp=sharing\">Unity Package</a>\n  </p>\n</p>\n\n\n<!-- ABOUT THE PROJECT -->\n<h2 id=\"About-The-Project\"><a href=\"#About-The-Project\" class=\"headerlink\" title=\"About The Project\"></a>About The Project</h2><p>Two AR character are assigned to two QR codes in this project, and will dance to each other while they meet in AR world. Dancing animation and music will begin when they start dancing.</p>\n<ul>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> Animation</li>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> Particle System</li>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> AR tags</li>\n</ul>\n<h3 id=\"Built-With\"><a href=\"#Built-With\" class=\"headerlink\" title=\"Built With\"></a>Built With</h3><ul>\n<li><a href=\"https://unity3d.com/\">Unity 2017.4.1</a></li>\n<li><a href=\"https://developer.vuforia.com/\">Vuforia</a></li>\n<li><a href=\"https://www.mixamo.com/\">Mixamo</a></li>\n</ul>\n"},{"title":"","date":"2020-11-01T10:14:03.000Z","_content":"\n# Employment History\n\n## FW Engineer\n**Silicon Motion**\n2021.01 - Now\n\n - Develop & Verify Security features according to [TCG](https://trustedcomputinggroup.org/) spec\n - Modularize features into Libraries for easier project management\n - Secure Boot Authentication\n - Firmware Update Verification\n - Threat Analysis and Risk Assessment\n - Develop automation scripts to improve working efficiency\n - Customize requirements & Firmware debug\n\n---\n---\n\n# Certificate\n- [ISO/SAE 21434](/attaches/Certificate-PoKai-Huang.pdf)\n\n---\n---\n\n# Education\n\n## Master's Degree\n**Institute of Computer Science and Engineering**  \nNational Chiao-Tung University, Taiwan\n2018 - 2020\n\n - Key Courses\n    - Machine Learning\n    - Deep Learning\n    - Computer Vision\n    - VR and AR\n    - User Center Interaction Design\n\n - Overall GPA\n    - 3.9/4.3\n\n---\n\n## Bachelor's Degree\n**Department of Communication Engineering**  \nNational Central University, Taiwan\n2013 - 2017\n\n - Overall GPA\n    - 3.0/4.3\n\n---\n---\n\n# Teaching Experience\n**Introduction to Computers and Programming, Dept. of Computer Science, NCTU**\nTeacher Assistant (C, Python)\n_2018 Fall_<br>\n**Python Programming**\nTutor\n_2019_<br>\n**Senior High School Math**\nTutor\n_2013 - 2020_\n\n---\n---\n\n# Skills\n* Programming Language\n    * C/C++\n    * Python\n* Skills\n    * [TCG Security](https://trustedcomputinggroup.org/)\n    * Secure Boot Authentication\n    * Firmware Update Verification\n    * API Modularize\n    * Unity\n    * Arduino\n* Language\n    * Mandarin\n    * English","source":"Resume/index.md","raw":"---\ntitle: \ndate: 2020-11-01 18:14:03\n---\n\n# Employment History\n\n## FW Engineer\n**Silicon Motion**\n2021.01 - Now\n\n - Develop & Verify Security features according to [TCG](https://trustedcomputinggroup.org/) spec\n - Modularize features into Libraries for easier project management\n - Secure Boot Authentication\n - Firmware Update Verification\n - Threat Analysis and Risk Assessment\n - Develop automation scripts to improve working efficiency\n - Customize requirements & Firmware debug\n\n---\n---\n\n# Certificate\n- [ISO/SAE 21434](/attaches/Certificate-PoKai-Huang.pdf)\n\n---\n---\n\n# Education\n\n## Master's Degree\n**Institute of Computer Science and Engineering**  \nNational Chiao-Tung University, Taiwan\n2018 - 2020\n\n - Key Courses\n    - Machine Learning\n    - Deep Learning\n    - Computer Vision\n    - VR and AR\n    - User Center Interaction Design\n\n - Overall GPA\n    - 3.9/4.3\n\n---\n\n## Bachelor's Degree\n**Department of Communication Engineering**  \nNational Central University, Taiwan\n2013 - 2017\n\n - Overall GPA\n    - 3.0/4.3\n\n---\n---\n\n# Teaching Experience\n**Introduction to Computers and Programming, Dept. of Computer Science, NCTU**\nTeacher Assistant (C, Python)\n_2018 Fall_<br>\n**Python Programming**\nTutor\n_2019_<br>\n**Senior High School Math**\nTutor\n_2013 - 2020_\n\n---\n---\n\n# Skills\n* Programming Language\n    * C/C++\n    * Python\n* Skills\n    * [TCG Security](https://trustedcomputinggroup.org/)\n    * Secure Boot Authentication\n    * Firmware Update Verification\n    * API Modularize\n    * Unity\n    * Arduino\n* Language\n    * Mandarin\n    * English","updated":"2024-01-15T15:04:23.842Z","path":"Resume/index.html","_id":"cl28njpbb0004vt22374516dg","comments":1,"layout":"page","content":"<h1 id=\"Employment-History\"><a href=\"#Employment-History\" class=\"headerlink\" title=\"Employment History\"></a>Employment History</h1><h2 id=\"FW-Engineer\"><a href=\"#FW-Engineer\" class=\"headerlink\" title=\"FW Engineer\"></a>FW Engineer</h2><p><strong>Silicon Motion</strong><br>2021.01 - Now</p>\n<ul>\n<li>Develop &amp; Verify Security features according to <a href=\"https://trustedcomputinggroup.org/\">TCG</a> spec</li>\n<li>Modularize features into Libraries for easier project management</li>\n<li>Secure Boot Authentication</li>\n<li>Firmware Update Verification</li>\n<li>Threat Analysis and Risk Assessment</li>\n<li>Develop automation scripts to improve working efficiency</li>\n<li>Customize requirements &amp; Firmware debug</li>\n</ul>\n<hr>\n<hr>\n<h1 id=\"Certificate\"><a href=\"#Certificate\" class=\"headerlink\" title=\"Certificate\"></a>Certificate</h1><ul>\n<li><a href=\"/attaches/Certificate-PoKai-Huang.pdf\">ISO&#x2F;SAE 21434</a></li>\n</ul>\n<hr>\n<hr>\n<h1 id=\"Education\"><a href=\"#Education\" class=\"headerlink\" title=\"Education\"></a>Education</h1><h2 id=\"Master’s-Degree\"><a href=\"#Master’s-Degree\" class=\"headerlink\" title=\"Master’s Degree\"></a>Master’s Degree</h2><p><strong>Institute of Computer Science and Engineering</strong><br>National Chiao-Tung University, Taiwan<br>2018 - 2020</p>\n<ul>\n<li><p>Key Courses</p>\n<ul>\n<li>Machine Learning</li>\n<li>Deep Learning</li>\n<li>Computer Vision</li>\n<li>VR and AR</li>\n<li>User Center Interaction Design</li>\n</ul>\n</li>\n<li><p>Overall GPA</p>\n<ul>\n<li>3.9&#x2F;4.3</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h2 id=\"Bachelor’s-Degree\"><a href=\"#Bachelor’s-Degree\" class=\"headerlink\" title=\"Bachelor’s Degree\"></a>Bachelor’s Degree</h2><p><strong>Department of Communication Engineering</strong><br>National Central University, Taiwan<br>2013 - 2017</p>\n<ul>\n<li>Overall GPA<ul>\n<li>3.0&#x2F;4.3</li>\n</ul>\n</li>\n</ul>\n<hr>\n<hr>\n<h1 id=\"Teaching-Experience\"><a href=\"#Teaching-Experience\" class=\"headerlink\" title=\"Teaching Experience\"></a>Teaching Experience</h1><p><strong>Introduction to Computers and Programming, Dept. of Computer Science, NCTU</strong><br>Teacher Assistant (C, Python)<br><em>2018 Fall</em><br><br><strong>Python Programming</strong><br>Tutor<br><em>2019</em><br><br><strong>Senior High School Math</strong><br>Tutor<br><em>2013 - 2020</em></p>\n<hr>\n<hr>\n<h1 id=\"Skills\"><a href=\"#Skills\" class=\"headerlink\" title=\"Skills\"></a>Skills</h1><ul>\n<li>Programming Language<ul>\n<li>C&#x2F;C++</li>\n<li>Python</li>\n</ul>\n</li>\n<li>Skills<ul>\n<li><a href=\"https://trustedcomputinggroup.org/\">TCG Security</a></li>\n<li>Secure Boot Authentication</li>\n<li>Firmware Update Verification</li>\n<li>API Modularize</li>\n<li>Unity</li>\n<li>Arduino</li>\n</ul>\n</li>\n<li>Language<ul>\n<li>Mandarin</li>\n<li>English</li>\n</ul>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"Employment-History\"><a href=\"#Employment-History\" class=\"headerlink\" title=\"Employment History\"></a>Employment History</h1><h2 id=\"FW-Engineer\"><a href=\"#FW-Engineer\" class=\"headerlink\" title=\"FW Engineer\"></a>FW Engineer</h2><p><strong>Silicon Motion</strong><br>2021.01 - Now</p>\n<ul>\n<li>Develop &amp; Verify Security features according to <a href=\"https://trustedcomputinggroup.org/\">TCG</a> spec</li>\n<li>Modularize features into Libraries for easier project management</li>\n<li>Secure Boot Authentication</li>\n<li>Firmware Update Verification</li>\n<li>Threat Analysis and Risk Assessment</li>\n<li>Develop automation scripts to improve working efficiency</li>\n<li>Customize requirements &amp; Firmware debug</li>\n</ul>\n<hr>\n<hr>\n<h1 id=\"Certificate\"><a href=\"#Certificate\" class=\"headerlink\" title=\"Certificate\"></a>Certificate</h1><ul>\n<li><a href=\"/attaches/Certificate-PoKai-Huang.pdf\">ISO&#x2F;SAE 21434</a></li>\n</ul>\n<hr>\n<hr>\n<h1 id=\"Education\"><a href=\"#Education\" class=\"headerlink\" title=\"Education\"></a>Education</h1><h2 id=\"Master’s-Degree\"><a href=\"#Master’s-Degree\" class=\"headerlink\" title=\"Master’s Degree\"></a>Master’s Degree</h2><p><strong>Institute of Computer Science and Engineering</strong><br>National Chiao-Tung University, Taiwan<br>2018 - 2020</p>\n<ul>\n<li><p>Key Courses</p>\n<ul>\n<li>Machine Learning</li>\n<li>Deep Learning</li>\n<li>Computer Vision</li>\n<li>VR and AR</li>\n<li>User Center Interaction Design</li>\n</ul>\n</li>\n<li><p>Overall GPA</p>\n<ul>\n<li>3.9&#x2F;4.3</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h2 id=\"Bachelor’s-Degree\"><a href=\"#Bachelor’s-Degree\" class=\"headerlink\" title=\"Bachelor’s Degree\"></a>Bachelor’s Degree</h2><p><strong>Department of Communication Engineering</strong><br>National Central University, Taiwan<br>2013 - 2017</p>\n<ul>\n<li>Overall GPA<ul>\n<li>3.0&#x2F;4.3</li>\n</ul>\n</li>\n</ul>\n<hr>\n<hr>\n<h1 id=\"Teaching-Experience\"><a href=\"#Teaching-Experience\" class=\"headerlink\" title=\"Teaching Experience\"></a>Teaching Experience</h1><p><strong>Introduction to Computers and Programming, Dept. of Computer Science, NCTU</strong><br>Teacher Assistant (C, Python)<br><em>2018 Fall</em><br><br><strong>Python Programming</strong><br>Tutor<br><em>2019</em><br><br><strong>Senior High School Math</strong><br>Tutor<br><em>2013 - 2020</em></p>\n<hr>\n<hr>\n<h1 id=\"Skills\"><a href=\"#Skills\" class=\"headerlink\" title=\"Skills\"></a>Skills</h1><ul>\n<li>Programming Language<ul>\n<li>C&#x2F;C++</li>\n<li>Python</li>\n</ul>\n</li>\n<li>Skills<ul>\n<li><a href=\"https://trustedcomputinggroup.org/\">TCG Security</a></li>\n<li>Secure Boot Authentication</li>\n<li>Firmware Update Verification</li>\n<li>API Modularize</li>\n<li>Unity</li>\n<li>Arduino</li>\n</ul>\n</li>\n<li>Language<ul>\n<li>Mandarin</li>\n<li>English</li>\n</ul>\n</li>\n</ul>\n"},{"title":"","date":"2020-11-03T02:38:21.000Z","_content":"\n<div>\n\t<h1 style=\"display:inline;\"> Music Box </h1> \n\t<a href=\"https://github.com/PKhuang-TW/Music-Box\"> [Code] </a> \n</div>\n\n---\n\n<!-- PROJECT LOGO -->\n<br />\n<p align=\"center\">\n    <img src=\"./imgs/3.jpg\" alt=\"MusicBox\" width=\"500\">\n  </a>\n  <h3 align=\"center\">Music Box</h3>\n  <p align=\"center\">\n    Self-Made Music Box\n    <br />\n    <a href=\"https://youtu.be/K19CnvB4NbM\">View Demo</a>\n  </p>\n</p>\n\n<!-- ABOUT THE PROJECT -->\n## About The Project\n\nThis is a **Self-Made Music Box** built with Arduino. Music will be read through SD module (LC-SD) and output by a 8-Ohm 2W speaker. Buttons on the box supports **Play/Stop, Next/Previous**; LCD was prepared to show music name. However, the LCD module doesn't support Traditional Chinese output, so the LCD was not implemented in this project finally.\n\n- [x] Read Music From SD card\n- [x] Play music from speaker\n- [x] Play/Stop, Next/Previous\n- [ ] Show information from LCD\n\n<p align=\"center\">\n    <img src=\"./imgs/3.jpg\" width=\"35%\">\n    <img src=\"./imgs/1.jpg\" width=\"35%\">\n    <br>\n    <img src=\"./imgs/2.jpg\" width=\"35%\">\n    <img src=\"./imgs/4.jpg\" width=\"35%\"> \n</p>\n\n### Built With\n\n* [Arduino Nano](https://store.arduino.cc/usa/arduino-nano)\n* [LC Technology SD Card Module LC-SD](https://www.amazon.co.uk/LC-Technology-Module-LC-SD-Arduino/dp/B01LWK2VCK)\n* 8-Ohm 2-W Speaker *1\n\n### Schematic\n<img src = \"./imgs/schematic.png\" class=\"projectDetailImg\">\n\n\n<!-- GETTING STARTED -->\n## Getting Started\n\n### Libraray\nImport all the libraries in ./Library/\n<p align=\"center\">\n  <img src=\"./imgs/importLibrary.png\" width=\"50%\">\n</p>  \n\n### Music Format\nMusic format must be .wav, 8 Bit resolution, 8 KHz sample rate, mono audio. You can convert your audio file with [this site](https://audio.online-convert.com/convert-to-wav).\n<img src = \"./imgs/ConvertEx.png\" class=\"projectDetailImg\">\n","source":"MusicBox/index.md","raw":"---\ntitle: \ndate: 2020-11-03 10:38:21\n---\n\n<div>\n\t<h1 style=\"display:inline;\"> Music Box </h1> \n\t<a href=\"https://github.com/PKhuang-TW/Music-Box\"> [Code] </a> \n</div>\n\n---\n\n<!-- PROJECT LOGO -->\n<br />\n<p align=\"center\">\n    <img src=\"./imgs/3.jpg\" alt=\"MusicBox\" width=\"500\">\n  </a>\n  <h3 align=\"center\">Music Box</h3>\n  <p align=\"center\">\n    Self-Made Music Box\n    <br />\n    <a href=\"https://youtu.be/K19CnvB4NbM\">View Demo</a>\n  </p>\n</p>\n\n<!-- ABOUT THE PROJECT -->\n## About The Project\n\nThis is a **Self-Made Music Box** built with Arduino. Music will be read through SD module (LC-SD) and output by a 8-Ohm 2W speaker. Buttons on the box supports **Play/Stop, Next/Previous**; LCD was prepared to show music name. However, the LCD module doesn't support Traditional Chinese output, so the LCD was not implemented in this project finally.\n\n- [x] Read Music From SD card\n- [x] Play music from speaker\n- [x] Play/Stop, Next/Previous\n- [ ] Show information from LCD\n\n<p align=\"center\">\n    <img src=\"./imgs/3.jpg\" width=\"35%\">\n    <img src=\"./imgs/1.jpg\" width=\"35%\">\n    <br>\n    <img src=\"./imgs/2.jpg\" width=\"35%\">\n    <img src=\"./imgs/4.jpg\" width=\"35%\"> \n</p>\n\n### Built With\n\n* [Arduino Nano](https://store.arduino.cc/usa/arduino-nano)\n* [LC Technology SD Card Module LC-SD](https://www.amazon.co.uk/LC-Technology-Module-LC-SD-Arduino/dp/B01LWK2VCK)\n* 8-Ohm 2-W Speaker *1\n\n### Schematic\n<img src = \"./imgs/schematic.png\" class=\"projectDetailImg\">\n\n\n<!-- GETTING STARTED -->\n## Getting Started\n\n### Libraray\nImport all the libraries in ./Library/\n<p align=\"center\">\n  <img src=\"./imgs/importLibrary.png\" width=\"50%\">\n</p>  \n\n### Music Format\nMusic format must be .wav, 8 Bit resolution, 8 KHz sample rate, mono audio. You can convert your audio file with [this site](https://audio.online-convert.com/convert-to-wav).\n<img src = \"./imgs/ConvertEx.png\" class=\"projectDetailImg\">\n","updated":"2024-01-12T13:45:57.921Z","path":"MusicBox/index.html","_id":"cl28njpbc0005vt22gfnm6fqo","comments":1,"layout":"page","content":"<div>\n    <h1 style=\"display:inline;\"> Music Box </h1> \n    <a href=\"https://github.com/PKhuang-TW/Music-Box\"> [Code] </a> \n</div>\n\n<hr>\n<!-- PROJECT LOGO -->\n<br />\n<p align=\"center\">\n    <img src=\"./imgs/3.jpg\" alt=\"MusicBox\" width=\"500\">\n  </a>\n  <h3 align=\"center\">Music Box</h3>\n  <p align=\"center\">\n    Self-Made Music Box\n    <br />\n    <a href=\"https://youtu.be/K19CnvB4NbM\">View Demo</a>\n  </p>\n</p>\n\n<!-- ABOUT THE PROJECT -->\n<h2 id=\"About-The-Project\"><a href=\"#About-The-Project\" class=\"headerlink\" title=\"About The Project\"></a>About The Project</h2><p>This is a <strong>Self-Made Music Box</strong> built with Arduino. Music will be read through SD module (LC-SD) and output by a 8-Ohm 2W speaker. Buttons on the box supports <strong>Play&#x2F;Stop, Next&#x2F;Previous</strong>; LCD was prepared to show music name. However, the LCD module doesn’t support Traditional Chinese output, so the LCD was not implemented in this project finally.</p>\n<ul>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> Read Music From SD card</li>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> Play music from speaker</li>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> Play&#x2F;Stop, Next&#x2F;Previous</li>\n<li><input disabled=\"\" type=\"checkbox\"> Show information from LCD</li>\n</ul>\n<p align=\"center\">\n    <img src=\"./imgs/3.jpg\" width=\"35%\">\n    <img src=\"./imgs/1.jpg\" width=\"35%\">\n    <br>\n    <img src=\"./imgs/2.jpg\" width=\"35%\">\n    <img src=\"./imgs/4.jpg\" width=\"35%\"> \n</p>\n\n<h3 id=\"Built-With\"><a href=\"#Built-With\" class=\"headerlink\" title=\"Built With\"></a>Built With</h3><ul>\n<li><a href=\"https://store.arduino.cc/usa/arduino-nano\">Arduino Nano</a></li>\n<li><a href=\"https://www.amazon.co.uk/LC-Technology-Module-LC-SD-Arduino/dp/B01LWK2VCK\">LC Technology SD Card Module LC-SD</a></li>\n<li>8-Ohm 2-W Speaker *1</li>\n</ul>\n<h3 id=\"Schematic\"><a href=\"#Schematic\" class=\"headerlink\" title=\"Schematic\"></a>Schematic</h3><img src = \"./imgs/schematic.png\" class=\"projectDetailImg\">\n\n\n<!-- GETTING STARTED -->\n<h2 id=\"Getting-Started\"><a href=\"#Getting-Started\" class=\"headerlink\" title=\"Getting Started\"></a>Getting Started</h2><h3 id=\"Libraray\"><a href=\"#Libraray\" class=\"headerlink\" title=\"Libraray\"></a>Libraray</h3><p>Import all the libraries in .&#x2F;Library&#x2F;</p>\n<p align=\"center\">\n  <img src=\"./imgs/importLibrary.png\" width=\"50%\">\n</p>  \n\n<h3 id=\"Music-Format\"><a href=\"#Music-Format\" class=\"headerlink\" title=\"Music Format\"></a>Music Format</h3><p>Music format must be .wav, 8 Bit resolution, 8 KHz sample rate, mono audio. You can convert your audio file with <a href=\"https://audio.online-convert.com/convert-to-wav\">this site</a>.<br><img src = \"./imgs/ConvertEx.png\" class=\"projectDetailImg\"></p>\n","site":{"data":{}},"excerpt":"","more":"<div>\n    <h1 style=\"display:inline;\"> Music Box </h1> \n    <a href=\"https://github.com/PKhuang-TW/Music-Box\"> [Code] </a> \n</div>\n\n<hr>\n<!-- PROJECT LOGO -->\n<br />\n<p align=\"center\">\n    <img src=\"./imgs/3.jpg\" alt=\"MusicBox\" width=\"500\">\n  </a>\n  <h3 align=\"center\">Music Box</h3>\n  <p align=\"center\">\n    Self-Made Music Box\n    <br />\n    <a href=\"https://youtu.be/K19CnvB4NbM\">View Demo</a>\n  </p>\n</p>\n\n<!-- ABOUT THE PROJECT -->\n<h2 id=\"About-The-Project\"><a href=\"#About-The-Project\" class=\"headerlink\" title=\"About The Project\"></a>About The Project</h2><p>This is a <strong>Self-Made Music Box</strong> built with Arduino. Music will be read through SD module (LC-SD) and output by a 8-Ohm 2W speaker. Buttons on the box supports <strong>Play&#x2F;Stop, Next&#x2F;Previous</strong>; LCD was prepared to show music name. However, the LCD module doesn’t support Traditional Chinese output, so the LCD was not implemented in this project finally.</p>\n<ul>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> Read Music From SD card</li>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> Play music from speaker</li>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> Play&#x2F;Stop, Next&#x2F;Previous</li>\n<li><input disabled=\"\" type=\"checkbox\"> Show information from LCD</li>\n</ul>\n<p align=\"center\">\n    <img src=\"./imgs/3.jpg\" width=\"35%\">\n    <img src=\"./imgs/1.jpg\" width=\"35%\">\n    <br>\n    <img src=\"./imgs/2.jpg\" width=\"35%\">\n    <img src=\"./imgs/4.jpg\" width=\"35%\"> \n</p>\n\n<h3 id=\"Built-With\"><a href=\"#Built-With\" class=\"headerlink\" title=\"Built With\"></a>Built With</h3><ul>\n<li><a href=\"https://store.arduino.cc/usa/arduino-nano\">Arduino Nano</a></li>\n<li><a href=\"https://www.amazon.co.uk/LC-Technology-Module-LC-SD-Arduino/dp/B01LWK2VCK\">LC Technology SD Card Module LC-SD</a></li>\n<li>8-Ohm 2-W Speaker *1</li>\n</ul>\n<h3 id=\"Schematic\"><a href=\"#Schematic\" class=\"headerlink\" title=\"Schematic\"></a>Schematic</h3><img src = \"./imgs/schematic.png\" class=\"projectDetailImg\">\n\n\n<!-- GETTING STARTED -->\n<h2 id=\"Getting-Started\"><a href=\"#Getting-Started\" class=\"headerlink\" title=\"Getting Started\"></a>Getting Started</h2><h3 id=\"Libraray\"><a href=\"#Libraray\" class=\"headerlink\" title=\"Libraray\"></a>Libraray</h3><p>Import all the libraries in .&#x2F;Library&#x2F;</p>\n<p align=\"center\">\n  <img src=\"./imgs/importLibrary.png\" width=\"50%\">\n</p>  \n\n<h3 id=\"Music-Format\"><a href=\"#Music-Format\" class=\"headerlink\" title=\"Music Format\"></a>Music Format</h3><p>Music format must be .wav, 8 Bit resolution, 8 KHz sample rate, mono audio. You can convert your audio file with <a href=\"https://audio.online-convert.com/convert-to-wav\">this site</a>.<br><img src = \"./imgs/ConvertEx.png\" class=\"projectDetailImg\"></p>\n"},{"title":"Projects","date":"2020-11-01T10:24:00.000Z","_content":"\n---\n### [Multi-Style Semantic Style Transfer](/MultiStyleNST/)\n\n<div\n    class = \"projectBox\">\n  <table>\n    <tr>\n      <th\n        class = \"imageColumn\">\n            <img src = \"MultiStyleNST.png\"\n            class = \"projectImg\">\n          </a>\n      </th>\n      <th\n        class = \"textColumn\">\n            This project is aimed to transfer different semantic objects in one image into different styles. We use pretrained semantic segmentation model (DeepLab-V3) to get the foregound and backgound region, and apply style transfer on different style for each region. In addition to style loss and content loss in traditional neural style transfer, we futher add style-blending loss and total variance loss to make the result more harmony when blending very different style. Also, we provide custom control of blending effect. \n      </th>\n    </tr>\n  </table>\n</div>\n\n---\n\n### [Enchanter](/Enchanter/)\n\n<div\n    class = \"projectBox\">\n  <table>\n    <tr>\n      <th\n        class = \"imageColumn\">\n            <img src = \"Enchanter.png\" width=\"800\"\n            class = \"projectImg\">\n          </a>\n      </th>\n      <th\n        class = \"textColumn\">\n            This is a <b>Multiplayer VR Game</b> with <b>Gesture Recognition</b>. Players fight against each other by casting magic spells drew by their VR controller. Enchanter is developed on HTC VIVE, and <a href=\"https://www.photonengine.com/zh-TW/Photon\">Photon</a> is used to synchronize the connection. A CNN model is trained to recognize gestures, with five spell symbols and one noise category. We have designed a total of nine skills, each of which has its own characteristics. Players can choose five corresponding spell symbols in the lobby. In addition, in order to prevent dizziness when the player moves in the game, we narrowed the field of view when the user turns his head or moves in the game.\n      </th>\n    </tr>\n  </table>\n</div>\n\n---\n\n### [Love is in the Air](https://bldpiqo.wixsite.com/ucidgroup1)\n\n<div\n    class = \"projectBox\">\n  <table>\n    <tr>\n      <th\n        class = \"imageColumn\">\n            <img src = \"Love-is-in-the-Air.jpg\"\n            class = \"projectImg\">\n          </a>\n      </th>\n      <th\n        class = \"textColumn\">\n            Couples tend to meetup regularly to maintain the relationship, and to keep in touch. Some of them might be disappointed by the distance or meetup frequency. We’d like to build the network to support these relationships, make them feel secure in the relationship. We conduct an interview and build up an affinity wall to narrow down to several key findings. A <b>Mouse</b> for couples is our design solution after creating personas. Finally, an usability test is conducted to evaluate our system.\n      </th>\n    </tr>\n  </table>\n</div>\n\n---\n\n### [Music Box](/MusicBox/)\n\n<div\n    class = \"projectBox\">\n  <table>\n    <tr>\n      <th\n        class = \"imageColumn\">\n        <img src = \"MusicBox.jpg\"\n            class = \"projectImg\">\n      </th>\n      <th\n        class = \"textColumn\">\n            This is a <b>Self-Made Music Box</b> built with Arduino. Music will be read through SD module (LC-SD) and output by a 8-Ohm 2W speaker. Buttons on the box supports <b>Play/Stop, Next/Previous</b> LCD was prepared to show music name. However, the LCD module doesn't support Traditional Chinese output, so the LCD was not implemented in this project finally.\n      </th>\n    </tr>\n  </table>\n</div>\n\n---\n\n\n### [CoinForest](/CoinForest/)\n<div\n    class = \"projectBox\">\n  <table>\n    <tr>\n      <th\n        class = \"imageColumn\">\n        <img src = \"CoinForest.png\"\n            class = \"projectImg\">\n      </th>\n      <th\n        class = \"textColumn\">\n            This is a <b>PC Game</b> built by Unity 3D. There are 10 coins in the world, player can either play again or exit after collecting all the coins. <I>Due to the computer performance is not very good, the recorded video is a bit lag, but there is no such phenomenon when playing.</I>\n      </th>\n    </tr>\n  </table>\n</div>\n\n\n---\n\n\n<!-- \n### [iRing](/iRing/)\n\n<div\n    class = \"projectBox\">\n  <table>\n    <tr>\n      <th\n        class = \"imageColumn\">\n        <img src = \"iRing.jpg\"\n            class = \"projectImg\">\n      </th>\n      <th\n        class = \"textColumn\">\n            This is a intelligent ring using <b>Infrared Reflection</b>. 4 IR sensors are attached on the 3D-printed Ring. Data from each sensor were collected in four states and was used to recognize current states in real time. The states are determined by the distance between finger and ring since the result will be different in each situation. Arduino and Python are used to collect data; Processing is used to build the interface.\n      </th>\n    </tr>\n  </table>\n</div>\n\n\n---\n\n\n### [HappyDancing](/HappyDancing/)\n<div\n    class = \"projectBox\">\n  <table>\n    <tr>\n      <th\n        class = \"imageColumn\">\n        <img src = \"HappyDancing.png\"\n            class = \"projectImg\">\n      </th>\n      <th\n        class = \"textColumn\">\n            Two AR character are assigned to two QR codes in this project, and will dance to each other while they meet in AR world. Dancing animation and music will begin when they start dancing.\n      </th>\n    </tr>\n  </table>\n</div> -->","source":"Projects/index.md","raw":"---\ntitle: Projects\ndate: 2020-11-01 18:24:00\n---\n\n---\n### [Multi-Style Semantic Style Transfer](/MultiStyleNST/)\n\n<div\n    class = \"projectBox\">\n  <table>\n    <tr>\n      <th\n        class = \"imageColumn\">\n            <img src = \"MultiStyleNST.png\"\n            class = \"projectImg\">\n          </a>\n      </th>\n      <th\n        class = \"textColumn\">\n            This project is aimed to transfer different semantic objects in one image into different styles. We use pretrained semantic segmentation model (DeepLab-V3) to get the foregound and backgound region, and apply style transfer on different style for each region. In addition to style loss and content loss in traditional neural style transfer, we futher add style-blending loss and total variance loss to make the result more harmony when blending very different style. Also, we provide custom control of blending effect. \n      </th>\n    </tr>\n  </table>\n</div>\n\n---\n\n### [Enchanter](/Enchanter/)\n\n<div\n    class = \"projectBox\">\n  <table>\n    <tr>\n      <th\n        class = \"imageColumn\">\n            <img src = \"Enchanter.png\" width=\"800\"\n            class = \"projectImg\">\n          </a>\n      </th>\n      <th\n        class = \"textColumn\">\n            This is a <b>Multiplayer VR Game</b> with <b>Gesture Recognition</b>. Players fight against each other by casting magic spells drew by their VR controller. Enchanter is developed on HTC VIVE, and <a href=\"https://www.photonengine.com/zh-TW/Photon\">Photon</a> is used to synchronize the connection. A CNN model is trained to recognize gestures, with five spell symbols and one noise category. We have designed a total of nine skills, each of which has its own characteristics. Players can choose five corresponding spell symbols in the lobby. In addition, in order to prevent dizziness when the player moves in the game, we narrowed the field of view when the user turns his head or moves in the game.\n      </th>\n    </tr>\n  </table>\n</div>\n\n---\n\n### [Love is in the Air](https://bldpiqo.wixsite.com/ucidgroup1)\n\n<div\n    class = \"projectBox\">\n  <table>\n    <tr>\n      <th\n        class = \"imageColumn\">\n            <img src = \"Love-is-in-the-Air.jpg\"\n            class = \"projectImg\">\n          </a>\n      </th>\n      <th\n        class = \"textColumn\">\n            Couples tend to meetup regularly to maintain the relationship, and to keep in touch. Some of them might be disappointed by the distance or meetup frequency. We’d like to build the network to support these relationships, make them feel secure in the relationship. We conduct an interview and build up an affinity wall to narrow down to several key findings. A <b>Mouse</b> for couples is our design solution after creating personas. Finally, an usability test is conducted to evaluate our system.\n      </th>\n    </tr>\n  </table>\n</div>\n\n---\n\n### [Music Box](/MusicBox/)\n\n<div\n    class = \"projectBox\">\n  <table>\n    <tr>\n      <th\n        class = \"imageColumn\">\n        <img src = \"MusicBox.jpg\"\n            class = \"projectImg\">\n      </th>\n      <th\n        class = \"textColumn\">\n            This is a <b>Self-Made Music Box</b> built with Arduino. Music will be read through SD module (LC-SD) and output by a 8-Ohm 2W speaker. Buttons on the box supports <b>Play/Stop, Next/Previous</b> LCD was prepared to show music name. However, the LCD module doesn't support Traditional Chinese output, so the LCD was not implemented in this project finally.\n      </th>\n    </tr>\n  </table>\n</div>\n\n---\n\n\n### [CoinForest](/CoinForest/)\n<div\n    class = \"projectBox\">\n  <table>\n    <tr>\n      <th\n        class = \"imageColumn\">\n        <img src = \"CoinForest.png\"\n            class = \"projectImg\">\n      </th>\n      <th\n        class = \"textColumn\">\n            This is a <b>PC Game</b> built by Unity 3D. There are 10 coins in the world, player can either play again or exit after collecting all the coins. <I>Due to the computer performance is not very good, the recorded video is a bit lag, but there is no such phenomenon when playing.</I>\n      </th>\n    </tr>\n  </table>\n</div>\n\n\n---\n\n\n<!-- \n### [iRing](/iRing/)\n\n<div\n    class = \"projectBox\">\n  <table>\n    <tr>\n      <th\n        class = \"imageColumn\">\n        <img src = \"iRing.jpg\"\n            class = \"projectImg\">\n      </th>\n      <th\n        class = \"textColumn\">\n            This is a intelligent ring using <b>Infrared Reflection</b>. 4 IR sensors are attached on the 3D-printed Ring. Data from each sensor were collected in four states and was used to recognize current states in real time. The states are determined by the distance between finger and ring since the result will be different in each situation. Arduino and Python are used to collect data; Processing is used to build the interface.\n      </th>\n    </tr>\n  </table>\n</div>\n\n\n---\n\n\n### [HappyDancing](/HappyDancing/)\n<div\n    class = \"projectBox\">\n  <table>\n    <tr>\n      <th\n        class = \"imageColumn\">\n        <img src = \"HappyDancing.png\"\n            class = \"projectImg\">\n      </th>\n      <th\n        class = \"textColumn\">\n            Two AR character are assigned to two QR codes in this project, and will dance to each other while they meet in AR world. Dancing animation and music will begin when they start dancing.\n      </th>\n    </tr>\n  </table>\n</div> -->","updated":"2024-01-15T14:34:00.001Z","path":"Projects/index.html","_id":"cl28njpbc0006vt22gv73h5oo","comments":1,"layout":"page","content":"<hr>\n<h3 id=\"Multi-Style-Semantic-Style-Transfer\"><a href=\"#Multi-Style-Semantic-Style-Transfer\" class=\"headerlink\" title=\"Multi-Style Semantic Style Transfer\"></a><a href=\"/MultiStyleNST/\">Multi-Style Semantic Style Transfer</a></h3><div\n    class = \"projectBox\">\n  <table>\n    <tr>\n      <th\n        class = \"imageColumn\">\n            <img src = \"MultiStyleNST.png\"\n            class = \"projectImg\">\n          </a>\n      </th>\n      <th\n        class = \"textColumn\">\n            This project is aimed to transfer different semantic objects in one image into different styles. We use pretrained semantic segmentation model (DeepLab-V3) to get the foregound and backgound region, and apply style transfer on different style for each region. In addition to style loss and content loss in traditional neural style transfer, we futher add style-blending loss and total variance loss to make the result more harmony when blending very different style. Also, we provide custom control of blending effect. \n      </th>\n    </tr>\n  </table>\n</div>\n\n<hr>\n<h3 id=\"Enchanter\"><a href=\"#Enchanter\" class=\"headerlink\" title=\"Enchanter\"></a><a href=\"/Enchanter/\">Enchanter</a></h3><div\n    class = \"projectBox\">\n  <table>\n    <tr>\n      <th\n        class = \"imageColumn\">\n            <img src = \"Enchanter.png\" width=\"800\"\n            class = \"projectImg\">\n          </a>\n      </th>\n      <th\n        class = \"textColumn\">\n            This is a <b>Multiplayer VR Game</b> with <b>Gesture Recognition</b>. Players fight against each other by casting magic spells drew by their VR controller. Enchanter is developed on HTC VIVE, and <a href=\"https://www.photonengine.com/zh-TW/Photon\">Photon</a> is used to synchronize the connection. A CNN model is trained to recognize gestures, with five spell symbols and one noise category. We have designed a total of nine skills, each of which has its own characteristics. Players can choose five corresponding spell symbols in the lobby. In addition, in order to prevent dizziness when the player moves in the game, we narrowed the field of view when the user turns his head or moves in the game.\n      </th>\n    </tr>\n  </table>\n</div>\n\n<hr>\n<h3 id=\"Love-is-in-the-Air\"><a href=\"#Love-is-in-the-Air\" class=\"headerlink\" title=\"Love is in the Air\"></a><a href=\"https://bldpiqo.wixsite.com/ucidgroup1\">Love is in the Air</a></h3><div\n    class = \"projectBox\">\n  <table>\n    <tr>\n      <th\n        class = \"imageColumn\">\n            <img src = \"Love-is-in-the-Air.jpg\"\n            class = \"projectImg\">\n          </a>\n      </th>\n      <th\n        class = \"textColumn\">\n            Couples tend to meetup regularly to maintain the relationship, and to keep in touch. Some of them might be disappointed by the distance or meetup frequency. We’d like to build the network to support these relationships, make them feel secure in the relationship. We conduct an interview and build up an affinity wall to narrow down to several key findings. A <b>Mouse</b> for couples is our design solution after creating personas. Finally, an usability test is conducted to evaluate our system.\n      </th>\n    </tr>\n  </table>\n</div>\n\n<hr>\n<h3 id=\"Music-Box\"><a href=\"#Music-Box\" class=\"headerlink\" title=\"Music Box\"></a><a href=\"/MusicBox/\">Music Box</a></h3><div\n    class = \"projectBox\">\n  <table>\n    <tr>\n      <th\n        class = \"imageColumn\">\n        <img src = \"MusicBox.jpg\"\n            class = \"projectImg\">\n      </th>\n      <th\n        class = \"textColumn\">\n            This is a <b>Self-Made Music Box</b> built with Arduino. Music will be read through SD module (LC-SD) and output by a 8-Ohm 2W speaker. Buttons on the box supports <b>Play/Stop, Next/Previous</b> LCD was prepared to show music name. However, the LCD module doesn't support Traditional Chinese output, so the LCD was not implemented in this project finally.\n      </th>\n    </tr>\n  </table>\n</div>\n\n<hr>\n<h3 id=\"CoinForest\"><a href=\"#CoinForest\" class=\"headerlink\" title=\"CoinForest\"></a><a href=\"/CoinForest/\">CoinForest</a></h3><div\n    class = \"projectBox\">\n  <table>\n    <tr>\n      <th\n        class = \"imageColumn\">\n        <img src = \"CoinForest.png\"\n            class = \"projectImg\">\n      </th>\n      <th\n        class = \"textColumn\">\n            This is a <b>PC Game</b> built by Unity 3D. There are 10 coins in the world, player can either play again or exit after collecting all the coins. <I>Due to the computer performance is not very good, the recorded video is a bit lag, but there is no such phenomenon when playing.</I>\n      </th>\n    </tr>\n  </table>\n</div>\n\n\n<hr>\n<!-- \n### [iRing](/iRing/)\n\n<div\n    class = \"projectBox\">\n  <table>\n    <tr>\n      <th\n        class = \"imageColumn\">\n        <img src = \"iRing.jpg\"\n            class = \"projectImg\">\n      </th>\n      <th\n        class = \"textColumn\">\n            This is a intelligent ring using <b>Infrared Reflection</b>. 4 IR sensors are attached on the 3D-printed Ring. Data from each sensor were collected in four states and was used to recognize current states in real time. The states are determined by the distance between finger and ring since the result will be different in each situation. Arduino and Python are used to collect data; Processing is used to build the interface.\n      </th>\n    </tr>\n  </table>\n</div>\n\n\n---\n\n\n### [HappyDancing](/HappyDancing/)\n<div\n    class = \"projectBox\">\n  <table>\n    <tr>\n      <th\n        class = \"imageColumn\">\n        <img src = \"HappyDancing.png\"\n            class = \"projectImg\">\n      </th>\n      <th\n        class = \"textColumn\">\n            Two AR character are assigned to two QR codes in this project, and will dance to each other while they meet in AR world. Dancing animation and music will begin when they start dancing.\n      </th>\n    </tr>\n  </table>\n</div> -->","site":{"data":{}},"excerpt":"","more":"<hr>\n<h3 id=\"Multi-Style-Semantic-Style-Transfer\"><a href=\"#Multi-Style-Semantic-Style-Transfer\" class=\"headerlink\" title=\"Multi-Style Semantic Style Transfer\"></a><a href=\"/MultiStyleNST/\">Multi-Style Semantic Style Transfer</a></h3><div\n    class = \"projectBox\">\n  <table>\n    <tr>\n      <th\n        class = \"imageColumn\">\n            <img src = \"MultiStyleNST.png\"\n            class = \"projectImg\">\n          </a>\n      </th>\n      <th\n        class = \"textColumn\">\n            This project is aimed to transfer different semantic objects in one image into different styles. We use pretrained semantic segmentation model (DeepLab-V3) to get the foregound and backgound region, and apply style transfer on different style for each region. In addition to style loss and content loss in traditional neural style transfer, we futher add style-blending loss and total variance loss to make the result more harmony when blending very different style. Also, we provide custom control of blending effect. \n      </th>\n    </tr>\n  </table>\n</div>\n\n<hr>\n<h3 id=\"Enchanter\"><a href=\"#Enchanter\" class=\"headerlink\" title=\"Enchanter\"></a><a href=\"/Enchanter/\">Enchanter</a></h3><div\n    class = \"projectBox\">\n  <table>\n    <tr>\n      <th\n        class = \"imageColumn\">\n            <img src = \"Enchanter.png\" width=\"800\"\n            class = \"projectImg\">\n          </a>\n      </th>\n      <th\n        class = \"textColumn\">\n            This is a <b>Multiplayer VR Game</b> with <b>Gesture Recognition</b>. Players fight against each other by casting magic spells drew by their VR controller. Enchanter is developed on HTC VIVE, and <a href=\"https://www.photonengine.com/zh-TW/Photon\">Photon</a> is used to synchronize the connection. A CNN model is trained to recognize gestures, with five spell symbols and one noise category. We have designed a total of nine skills, each of which has its own characteristics. Players can choose five corresponding spell symbols in the lobby. In addition, in order to prevent dizziness when the player moves in the game, we narrowed the field of view when the user turns his head or moves in the game.\n      </th>\n    </tr>\n  </table>\n</div>\n\n<hr>\n<h3 id=\"Love-is-in-the-Air\"><a href=\"#Love-is-in-the-Air\" class=\"headerlink\" title=\"Love is in the Air\"></a><a href=\"https://bldpiqo.wixsite.com/ucidgroup1\">Love is in the Air</a></h3><div\n    class = \"projectBox\">\n  <table>\n    <tr>\n      <th\n        class = \"imageColumn\">\n            <img src = \"Love-is-in-the-Air.jpg\"\n            class = \"projectImg\">\n          </a>\n      </th>\n      <th\n        class = \"textColumn\">\n            Couples tend to meetup regularly to maintain the relationship, and to keep in touch. Some of them might be disappointed by the distance or meetup frequency. We’d like to build the network to support these relationships, make them feel secure in the relationship. We conduct an interview and build up an affinity wall to narrow down to several key findings. A <b>Mouse</b> for couples is our design solution after creating personas. Finally, an usability test is conducted to evaluate our system.\n      </th>\n    </tr>\n  </table>\n</div>\n\n<hr>\n<h3 id=\"Music-Box\"><a href=\"#Music-Box\" class=\"headerlink\" title=\"Music Box\"></a><a href=\"/MusicBox/\">Music Box</a></h3><div\n    class = \"projectBox\">\n  <table>\n    <tr>\n      <th\n        class = \"imageColumn\">\n        <img src = \"MusicBox.jpg\"\n            class = \"projectImg\">\n      </th>\n      <th\n        class = \"textColumn\">\n            This is a <b>Self-Made Music Box</b> built with Arduino. Music will be read through SD module (LC-SD) and output by a 8-Ohm 2W speaker. Buttons on the box supports <b>Play/Stop, Next/Previous</b> LCD was prepared to show music name. However, the LCD module doesn't support Traditional Chinese output, so the LCD was not implemented in this project finally.\n      </th>\n    </tr>\n  </table>\n</div>\n\n<hr>\n<h3 id=\"CoinForest\"><a href=\"#CoinForest\" class=\"headerlink\" title=\"CoinForest\"></a><a href=\"/CoinForest/\">CoinForest</a></h3><div\n    class = \"projectBox\">\n  <table>\n    <tr>\n      <th\n        class = \"imageColumn\">\n        <img src = \"CoinForest.png\"\n            class = \"projectImg\">\n      </th>\n      <th\n        class = \"textColumn\">\n            This is a <b>PC Game</b> built by Unity 3D. There are 10 coins in the world, player can either play again or exit after collecting all the coins. <I>Due to the computer performance is not very good, the recorded video is a bit lag, but there is no such phenomenon when playing.</I>\n      </th>\n    </tr>\n  </table>\n</div>\n\n\n<hr>\n<!-- \n### [iRing](/iRing/)\n\n<div\n    class = \"projectBox\">\n  <table>\n    <tr>\n      <th\n        class = \"imageColumn\">\n        <img src = \"iRing.jpg\"\n            class = \"projectImg\">\n      </th>\n      <th\n        class = \"textColumn\">\n            This is a intelligent ring using <b>Infrared Reflection</b>. 4 IR sensors are attached on the 3D-printed Ring. Data from each sensor were collected in four states and was used to recognize current states in real time. The states are determined by the distance between finger and ring since the result will be different in each situation. Arduino and Python are used to collect data; Processing is used to build the interface.\n      </th>\n    </tr>\n  </table>\n</div>\n\n\n---\n\n\n### [HappyDancing](/HappyDancing/)\n<div\n    class = \"projectBox\">\n  <table>\n    <tr>\n      <th\n        class = \"imageColumn\">\n        <img src = \"HappyDancing.png\"\n            class = \"projectImg\">\n      </th>\n      <th\n        class = \"textColumn\">\n            Two AR character are assigned to two QR codes in this project, and will dance to each other while they meet in AR world. Dancing animation and music will begin when they start dancing.\n      </th>\n    </tr>\n  </table>\n</div> -->"},{"title":"","date":"2020-11-04T11:45:21.000Z","_content":"\n## Eliciting Gestures on One Ear as a Centralize, Deformable Touch Interface\n\n### Abstract\nThe external structure of the ear, or the auricle, is of complex form and has various degrees of softness, allowing a huge potential for interaction design. Opportunities for affordances around the auricle are abundant: the irregular shape accommodates interfaces for buttons and sliders; the elasticity gives the degree of freedom for switches; the softness of the earlobe allows it to be pulled as a trigger. In addition, on-ear gestures provide occlusion-free manipulation compared to eye-hand interaction, which enable users to interact with objects without hand occlusion. Previous studies have primarily explored the ear as a touch interface at large owing to limitations of sensing technology. To uncover the potentials of the ear as a centralized, deformable, occlusion-free, touch interface, we conducted a user elicitation study of on-ear gestures. We extend the existing compilation of consensus gesture sets to account for n first preferable gestures, leading to the n-rank consensus gesture set that puts acceptance of gestures in the first place. Our findings provide guidance for designs of future sensors and on-ear interaction.\n","source":"Thesis/index.md","raw":"---\ntitle: \ndate: 2020-11-04 19:45:21\n---\n\n## Eliciting Gestures on One Ear as a Centralize, Deformable Touch Interface\n\n### Abstract\nThe external structure of the ear, or the auricle, is of complex form and has various degrees of softness, allowing a huge potential for interaction design. Opportunities for affordances around the auricle are abundant: the irregular shape accommodates interfaces for buttons and sliders; the elasticity gives the degree of freedom for switches; the softness of the earlobe allows it to be pulled as a trigger. In addition, on-ear gestures provide occlusion-free manipulation compared to eye-hand interaction, which enable users to interact with objects without hand occlusion. Previous studies have primarily explored the ear as a touch interface at large owing to limitations of sensing technology. To uncover the potentials of the ear as a centralized, deformable, occlusion-free, touch interface, we conducted a user elicitation study of on-ear gestures. We extend the existing compilation of consensus gesture sets to account for n first preferable gestures, leading to the n-rank consensus gesture set that puts acceptance of gestures in the first place. Our findings provide guidance for designs of future sensors and on-ear interaction.\n","updated":"2024-01-15T14:34:45.748Z","path":"Thesis/index.html","_id":"cl28njpbe0007vt223ps7dbwp","comments":1,"layout":"page","content":"<h2 id=\"Eliciting-Gestures-on-One-Ear-as-a-Centralize-Deformable-Touch-Interface\"><a href=\"#Eliciting-Gestures-on-One-Ear-as-a-Centralize-Deformable-Touch-Interface\" class=\"headerlink\" title=\"Eliciting Gestures on One Ear as a Centralize, Deformable Touch Interface\"></a>Eliciting Gestures on One Ear as a Centralize, Deformable Touch Interface</h2><h3 id=\"Abstract\"><a href=\"#Abstract\" class=\"headerlink\" title=\"Abstract\"></a>Abstract</h3><p>The external structure of the ear, or the auricle, is of complex form and has various degrees of softness, allowing a huge potential for interaction design. Opportunities for affordances around the auricle are abundant: the irregular shape accommodates interfaces for buttons and sliders; the elasticity gives the degree of freedom for switches; the softness of the earlobe allows it to be pulled as a trigger. In addition, on-ear gestures provide occlusion-free manipulation compared to eye-hand interaction, which enable users to interact with objects without hand occlusion. Previous studies have primarily explored the ear as a touch interface at large owing to limitations of sensing technology. To uncover the potentials of the ear as a centralized, deformable, occlusion-free, touch interface, we conducted a user elicitation study of on-ear gestures. We extend the existing compilation of consensus gesture sets to account for n first preferable gestures, leading to the n-rank consensus gesture set that puts acceptance of gestures in the first place. Our findings provide guidance for designs of future sensors and on-ear interaction.</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"Eliciting-Gestures-on-One-Ear-as-a-Centralize-Deformable-Touch-Interface\"><a href=\"#Eliciting-Gestures-on-One-Ear-as-a-Centralize-Deformable-Touch-Interface\" class=\"headerlink\" title=\"Eliciting Gestures on One Ear as a Centralize, Deformable Touch Interface\"></a>Eliciting Gestures on One Ear as a Centralize, Deformable Touch Interface</h2><h3 id=\"Abstract\"><a href=\"#Abstract\" class=\"headerlink\" title=\"Abstract\"></a>Abstract</h3><p>The external structure of the ear, or the auricle, is of complex form and has various degrees of softness, allowing a huge potential for interaction design. Opportunities for affordances around the auricle are abundant: the irregular shape accommodates interfaces for buttons and sliders; the elasticity gives the degree of freedom for switches; the softness of the earlobe allows it to be pulled as a trigger. In addition, on-ear gestures provide occlusion-free manipulation compared to eye-hand interaction, which enable users to interact with objects without hand occlusion. Previous studies have primarily explored the ear as a touch interface at large owing to limitations of sensing technology. To uncover the potentials of the ear as a centralized, deformable, occlusion-free, touch interface, we conducted a user elicitation study of on-ear gestures. We extend the existing compilation of consensus gesture sets to account for n first preferable gestures, leading to the n-rank consensus gesture set that puts acceptance of gestures in the first place. Our findings provide guidance for designs of future sensors and on-ear interaction.</p>\n"},{"title":"","date":"2020-11-03T11:59:31.000Z","_content":"\n<div>\n\t<h1 style=\"display:inline;\"> iRing </h1> \n\t<a href=\"https://github.com/PKhuang-TW/iRing\"> [Code] </a> \n</div>\n\n---\n\n\n<!-- PROJECT LOGO -->\n<br />\n<p align=\"center\">\n  <a href=\"https://github.com/PKhuang-TW/iRing/blob/master/imgs/poster.png\">\n    <img src=\"imgs/iRing.jpg\" width=\"350\">\n  </a>\n  <h3 align=\"center\">iRing</h3>\n  <p align=\"center\">\n    Intelligent Ring Using Infrared Reflection\n    <br />\n    <a href=\"https://youtu.be/65YDXLv2ujc\">View Demo</a>\n  </p>\n</p>\n\n\n<!-- ABOUT THE PROJECT -->\n## About The Project\n\nThis is a intelligent ring using **Infrared Reflection**. 4 IR sensors are attached on the 3D-printed Ring. Data from each sensor were collected in four states and was used to recognize current states in real time. \n  1. Not Wearing\n  2. Wearing (0, 90, 180, 270 degree)\n  3. Bending\n  4. Pressing\n\nThe states are determined by the distance between finger and ring since the result will be different during each situation. Arduino and Python are used to collect data; Processing is used to build the interface.\n\n\n### Built With\n\n* Arduino UNO\n* [IR sensor - QRE1113](https://www.sparkfun.com/products/9453)\n* 3D-Printed Ring\n* [Processing](https://processing.org)\n\n\n## Demo Images\niRing is able to recognize 4 states: Not Wearing, Wearing, Bending and Pressing. \n\n#### Histogram\nThe X-axis of the histogram is Sensor number; Y-axis is the received data of the sensor. \n<p align=\"center\">\n  <img src=\"./imgs/histogram.jpeg\" width=\"300\">\n</p>\n\n#### Orientation\nThe number in the circle shows the Sensor number, which is able to tell the orientation of iRing.\n<p align=\"center\">\n  <img src=\"imgs/orientation.jpeg\" width=\"300\">\n</p>\n\n### Not Wearing\nNothing blocks the IR sensor while not wearing, the received data of the sensors = 255.\n<p align=\"center\">\n  <img src=\"imgs/notWearing.png\" width=\"550\">\n</p>\n\n### Wearing\nWhile wearing the ring, distance between ring and finger is in average. We can also tell the orientation of the ring from the picture in the upper left corner.\n<p align=\"center\">\n  <img src=\"imgs/wearing.png\" width=\"550\">\n</p>\n\n### Bending\nData jitters while bending finger.\n<p align=\"center\">\n  <img src=\"imgs/bending.png\" width=\"550\">\n</p>\n\n### Pressing\nOne of the received data will be significantly larger when pressing sensor.\n<p align=\"center\">\n  <img src=\"imgs/pressing-1.png\" width=\"550\">\n  <img src=\"imgs/pressing-2.png\" width=\"550\">\n</p>","source":"iRing/index.md","raw":"---\ntitle: \ndate: 2020-11-03 19:59:31\n---\n\n<div>\n\t<h1 style=\"display:inline;\"> iRing </h1> \n\t<a href=\"https://github.com/PKhuang-TW/iRing\"> [Code] </a> \n</div>\n\n---\n\n\n<!-- PROJECT LOGO -->\n<br />\n<p align=\"center\">\n  <a href=\"https://github.com/PKhuang-TW/iRing/blob/master/imgs/poster.png\">\n    <img src=\"imgs/iRing.jpg\" width=\"350\">\n  </a>\n  <h3 align=\"center\">iRing</h3>\n  <p align=\"center\">\n    Intelligent Ring Using Infrared Reflection\n    <br />\n    <a href=\"https://youtu.be/65YDXLv2ujc\">View Demo</a>\n  </p>\n</p>\n\n\n<!-- ABOUT THE PROJECT -->\n## About The Project\n\nThis is a intelligent ring using **Infrared Reflection**. 4 IR sensors are attached on the 3D-printed Ring. Data from each sensor were collected in four states and was used to recognize current states in real time. \n  1. Not Wearing\n  2. Wearing (0, 90, 180, 270 degree)\n  3. Bending\n  4. Pressing\n\nThe states are determined by the distance between finger and ring since the result will be different during each situation. Arduino and Python are used to collect data; Processing is used to build the interface.\n\n\n### Built With\n\n* Arduino UNO\n* [IR sensor - QRE1113](https://www.sparkfun.com/products/9453)\n* 3D-Printed Ring\n* [Processing](https://processing.org)\n\n\n## Demo Images\niRing is able to recognize 4 states: Not Wearing, Wearing, Bending and Pressing. \n\n#### Histogram\nThe X-axis of the histogram is Sensor number; Y-axis is the received data of the sensor. \n<p align=\"center\">\n  <img src=\"./imgs/histogram.jpeg\" width=\"300\">\n</p>\n\n#### Orientation\nThe number in the circle shows the Sensor number, which is able to tell the orientation of iRing.\n<p align=\"center\">\n  <img src=\"imgs/orientation.jpeg\" width=\"300\">\n</p>\n\n### Not Wearing\nNothing blocks the IR sensor while not wearing, the received data of the sensors = 255.\n<p align=\"center\">\n  <img src=\"imgs/notWearing.png\" width=\"550\">\n</p>\n\n### Wearing\nWhile wearing the ring, distance between ring and finger is in average. We can also tell the orientation of the ring from the picture in the upper left corner.\n<p align=\"center\">\n  <img src=\"imgs/wearing.png\" width=\"550\">\n</p>\n\n### Bending\nData jitters while bending finger.\n<p align=\"center\">\n  <img src=\"imgs/bending.png\" width=\"550\">\n</p>\n\n### Pressing\nOne of the received data will be significantly larger when pressing sensor.\n<p align=\"center\">\n  <img src=\"imgs/pressing-1.png\" width=\"550\">\n  <img src=\"imgs/pressing-2.png\" width=\"550\">\n</p>","updated":"2024-01-12T13:45:57.964Z","path":"iRing/index.html","_id":"cl28njpbh0009vt22h1ntb2ut","comments":1,"layout":"page","content":"<div>\n    <h1 style=\"display:inline;\"> iRing </h1> \n    <a href=\"https://github.com/PKhuang-TW/iRing\"> [Code] </a> \n</div>\n\n<hr>\n<!-- PROJECT LOGO -->\n<br />\n<p align=\"center\">\n  <a href=\"https://github.com/PKhuang-TW/iRing/blob/master/imgs/poster.png\">\n    <img src=\"imgs/iRing.jpg\" width=\"350\">\n  </a>\n  <h3 align=\"center\">iRing</h3>\n  <p align=\"center\">\n    Intelligent Ring Using Infrared Reflection\n    <br />\n    <a href=\"https://youtu.be/65YDXLv2ujc\">View Demo</a>\n  </p>\n</p>\n\n\n<!-- ABOUT THE PROJECT -->\n<h2 id=\"About-The-Project\"><a href=\"#About-The-Project\" class=\"headerlink\" title=\"About The Project\"></a>About The Project</h2><p>This is a intelligent ring using <strong>Infrared Reflection</strong>. 4 IR sensors are attached on the 3D-printed Ring. Data from each sensor were collected in four states and was used to recognize current states in real time. </p>\n<ol>\n<li>Not Wearing</li>\n<li>Wearing (0, 90, 180, 270 degree)</li>\n<li>Bending</li>\n<li>Pressing</li>\n</ol>\n<p>The states are determined by the distance between finger and ring since the result will be different during each situation. Arduino and Python are used to collect data; Processing is used to build the interface.</p>\n<h3 id=\"Built-With\"><a href=\"#Built-With\" class=\"headerlink\" title=\"Built With\"></a>Built With</h3><ul>\n<li>Arduino UNO</li>\n<li><a href=\"https://www.sparkfun.com/products/9453\">IR sensor - QRE1113</a></li>\n<li>3D-Printed Ring</li>\n<li><a href=\"https://processing.org/\">Processing</a></li>\n</ul>\n<h2 id=\"Demo-Images\"><a href=\"#Demo-Images\" class=\"headerlink\" title=\"Demo Images\"></a>Demo Images</h2><p>iRing is able to recognize 4 states: Not Wearing, Wearing, Bending and Pressing. </p>\n<h4 id=\"Histogram\"><a href=\"#Histogram\" class=\"headerlink\" title=\"Histogram\"></a>Histogram</h4><p>The X-axis of the histogram is Sensor number; Y-axis is the received data of the sensor. </p>\n<p align=\"center\">\n  <img src=\"./imgs/histogram.jpeg\" width=\"300\">\n</p>\n\n<h4 id=\"Orientation\"><a href=\"#Orientation\" class=\"headerlink\" title=\"Orientation\"></a>Orientation</h4><p>The number in the circle shows the Sensor number, which is able to tell the orientation of iRing.</p>\n<p align=\"center\">\n  <img src=\"imgs/orientation.jpeg\" width=\"300\">\n</p>\n\n<h3 id=\"Not-Wearing\"><a href=\"#Not-Wearing\" class=\"headerlink\" title=\"Not Wearing\"></a>Not Wearing</h3><p>Nothing blocks the IR sensor while not wearing, the received data of the sensors &#x3D; 255.</p>\n<p align=\"center\">\n  <img src=\"imgs/notWearing.png\" width=\"550\">\n</p>\n\n<h3 id=\"Wearing\"><a href=\"#Wearing\" class=\"headerlink\" title=\"Wearing\"></a>Wearing</h3><p>While wearing the ring, distance between ring and finger is in average. We can also tell the orientation of the ring from the picture in the upper left corner.</p>\n<p align=\"center\">\n  <img src=\"imgs/wearing.png\" width=\"550\">\n</p>\n\n<h3 id=\"Bending\"><a href=\"#Bending\" class=\"headerlink\" title=\"Bending\"></a>Bending</h3><p>Data jitters while bending finger.</p>\n<p align=\"center\">\n  <img src=\"imgs/bending.png\" width=\"550\">\n</p>\n\n<h3 id=\"Pressing\"><a href=\"#Pressing\" class=\"headerlink\" title=\"Pressing\"></a>Pressing</h3><p>One of the received data will be significantly larger when pressing sensor.</p>\n<p align=\"center\">\n  <img src=\"imgs/pressing-1.png\" width=\"550\">\n  <img src=\"imgs/pressing-2.png\" width=\"550\">\n</p>","site":{"data":{}},"excerpt":"","more":"<div>\n    <h1 style=\"display:inline;\"> iRing </h1> \n    <a href=\"https://github.com/PKhuang-TW/iRing\"> [Code] </a> \n</div>\n\n<hr>\n<!-- PROJECT LOGO -->\n<br />\n<p align=\"center\">\n  <a href=\"https://github.com/PKhuang-TW/iRing/blob/master/imgs/poster.png\">\n    <img src=\"imgs/iRing.jpg\" width=\"350\">\n  </a>\n  <h3 align=\"center\">iRing</h3>\n  <p align=\"center\">\n    Intelligent Ring Using Infrared Reflection\n    <br />\n    <a href=\"https://youtu.be/65YDXLv2ujc\">View Demo</a>\n  </p>\n</p>\n\n\n<!-- ABOUT THE PROJECT -->\n<h2 id=\"About-The-Project\"><a href=\"#About-The-Project\" class=\"headerlink\" title=\"About The Project\"></a>About The Project</h2><p>This is a intelligent ring using <strong>Infrared Reflection</strong>. 4 IR sensors are attached on the 3D-printed Ring. Data from each sensor were collected in four states and was used to recognize current states in real time. </p>\n<ol>\n<li>Not Wearing</li>\n<li>Wearing (0, 90, 180, 270 degree)</li>\n<li>Bending</li>\n<li>Pressing</li>\n</ol>\n<p>The states are determined by the distance between finger and ring since the result will be different during each situation. Arduino and Python are used to collect data; Processing is used to build the interface.</p>\n<h3 id=\"Built-With\"><a href=\"#Built-With\" class=\"headerlink\" title=\"Built With\"></a>Built With</h3><ul>\n<li>Arduino UNO</li>\n<li><a href=\"https://www.sparkfun.com/products/9453\">IR sensor - QRE1113</a></li>\n<li>3D-Printed Ring</li>\n<li><a href=\"https://processing.org/\">Processing</a></li>\n</ul>\n<h2 id=\"Demo-Images\"><a href=\"#Demo-Images\" class=\"headerlink\" title=\"Demo Images\"></a>Demo Images</h2><p>iRing is able to recognize 4 states: Not Wearing, Wearing, Bending and Pressing. </p>\n<h4 id=\"Histogram\"><a href=\"#Histogram\" class=\"headerlink\" title=\"Histogram\"></a>Histogram</h4><p>The X-axis of the histogram is Sensor number; Y-axis is the received data of the sensor. </p>\n<p align=\"center\">\n  <img src=\"./imgs/histogram.jpeg\" width=\"300\">\n</p>\n\n<h4 id=\"Orientation\"><a href=\"#Orientation\" class=\"headerlink\" title=\"Orientation\"></a>Orientation</h4><p>The number in the circle shows the Sensor number, which is able to tell the orientation of iRing.</p>\n<p align=\"center\">\n  <img src=\"imgs/orientation.jpeg\" width=\"300\">\n</p>\n\n<h3 id=\"Not-Wearing\"><a href=\"#Not-Wearing\" class=\"headerlink\" title=\"Not Wearing\"></a>Not Wearing</h3><p>Nothing blocks the IR sensor while not wearing, the received data of the sensors &#x3D; 255.</p>\n<p align=\"center\">\n  <img src=\"imgs/notWearing.png\" width=\"550\">\n</p>\n\n<h3 id=\"Wearing\"><a href=\"#Wearing\" class=\"headerlink\" title=\"Wearing\"></a>Wearing</h3><p>While wearing the ring, distance between ring and finger is in average. We can also tell the orientation of the ring from the picture in the upper left corner.</p>\n<p align=\"center\">\n  <img src=\"imgs/wearing.png\" width=\"550\">\n</p>\n\n<h3 id=\"Bending\"><a href=\"#Bending\" class=\"headerlink\" title=\"Bending\"></a>Bending</h3><p>Data jitters while bending finger.</p>\n<p align=\"center\">\n  <img src=\"imgs/bending.png\" width=\"550\">\n</p>\n\n<h3 id=\"Pressing\"><a href=\"#Pressing\" class=\"headerlink\" title=\"Pressing\"></a>Pressing</h3><p>One of the received data will be significantly larger when pressing sensor.</p>\n<p align=\"center\">\n  <img src=\"imgs/pressing-1.png\" width=\"550\">\n  <img src=\"imgs/pressing-2.png\" width=\"550\">\n</p>"}],"Post":[{"title":"home","academia":true,"date":"2020-11-03T01:46:54.000Z","_content":"\n# PoKai Huang\nI am PoKai Huang, graduated from [Prof. Liwei Chan](https://people.cs.nctu.edu.tw/~liweichan/)'s Lab, the Institute of Computer Science and Engineering of National Chiao Tung University (NCTU), in 2020. My research area is Human-Computer Interaction (HCI), mainly focused on exploring the possibility of novel interaction. My master thesis **\"Eliciting Gestures on One Ear as a Centralize, Deformable Touch Interface\"** explores the possibility of on-ear interaction, and has been submitted to [CHI 2021](https://chi2021.acm.org).<p>\n\nI am a lively and enthusiastic person. In college, I have participated in many camps and clubs, and I served as an event leader to plan activities many times. Therefore, I am very familiar with communicating with a team and find compromises that everyone can agree on. Also, I have 6-7 years of tutoring experience, which has helped me to improve my communication skills.\n\nI have been working as a **firmware engineer** at SiliconMotion since 2021. During this time, I have developed security features according to [TCG](https://trustedcomputinggroup.org/) spec, customized requirements, and fixed various of firmware bugs. I have <u>modularized verification scripts to make developing new scripts easier</u>. Additionally, I have <u>extracted features from firmware and transplanted them into libraries</u>. I am also familiar with <u>Secure Boot Authentication</u> and <u>Firmware Update Verification</u>.\n\nAlthough, as a firmware engineer, it is not easy to switch to a different product line, I believe that facing new challenges can help me to improve myself constantly. In the future, I hope I can learn and master new architectures quickly to become a valuable asset ASAP.","source":"_posts/home.md","raw":"---\ntitle: home\nacademia: true\ndate: 2020-11-03 09:46:54\n---\n\n# PoKai Huang\nI am PoKai Huang, graduated from [Prof. Liwei Chan](https://people.cs.nctu.edu.tw/~liweichan/)'s Lab, the Institute of Computer Science and Engineering of National Chiao Tung University (NCTU), in 2020. My research area is Human-Computer Interaction (HCI), mainly focused on exploring the possibility of novel interaction. My master thesis **\"Eliciting Gestures on One Ear as a Centralize, Deformable Touch Interface\"** explores the possibility of on-ear interaction, and has been submitted to [CHI 2021](https://chi2021.acm.org).<p>\n\nI am a lively and enthusiastic person. In college, I have participated in many camps and clubs, and I served as an event leader to plan activities many times. Therefore, I am very familiar with communicating with a team and find compromises that everyone can agree on. Also, I have 6-7 years of tutoring experience, which has helped me to improve my communication skills.\n\nI have been working as a **firmware engineer** at SiliconMotion since 2021. During this time, I have developed security features according to [TCG](https://trustedcomputinggroup.org/) spec, customized requirements, and fixed various of firmware bugs. I have <u>modularized verification scripts to make developing new scripts easier</u>. Additionally, I have <u>extracted features from firmware and transplanted them into libraries</u>. I am also familiar with <u>Secure Boot Authentication</u> and <u>Firmware Update Verification</u>.\n\nAlthough, as a firmware engineer, it is not easy to switch to a different product line, I believe that facing new challenges can help me to improve myself constantly. In the future, I hope I can learn and master new architectures quickly to become a valuable asset ASAP.","slug":"home","published":1,"updated":"2024-01-15T14:55:25.477Z","_id":"cl28njpbf0008vt22ci5oaon3","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"PoKai-Huang\"><a href=\"#PoKai-Huang\" class=\"headerlink\" title=\"PoKai Huang\"></a>PoKai Huang</h1><p>I am PoKai Huang, graduated from <a href=\"https://people.cs.nctu.edu.tw/~liweichan/\">Prof. Liwei Chan</a>‘s Lab, the Institute of Computer Science and Engineering of National Chiao Tung University (NCTU), in 2020. My research area is Human-Computer Interaction (HCI), mainly focused on exploring the possibility of novel interaction. My master thesis <strong>“Eliciting Gestures on One Ear as a Centralize, Deformable Touch Interface”</strong> explores the possibility of on-ear interaction, and has been submitted to <a href=\"https://chi2021.acm.org/\">CHI 2021</a>.<p></p>\n<p>I am a lively and enthusiastic person. In college, I have participated in many camps and clubs, and I served as an event leader to plan activities many times. Therefore, I am very familiar with communicating with a team and find compromises that everyone can agree on. Also, I have 6-7 years of tutoring experience, which has helped me to improve my communication skills.</p>\n<p>I have been working as a <strong>firmware engineer</strong> at SiliconMotion since 2021. During this time, I have developed security features according to <a href=\"https://trustedcomputinggroup.org/\">TCG</a> spec, customized requirements, and fixed various of firmware bugs. I have <u>modularized verification scripts to make developing new scripts easier</u>. Additionally, I have <u>extracted features from firmware and transplanted them into libraries</u>. I am also familiar with <u>Secure Boot Authentication</u> and <u>Firmware Update Verification</u>.</p>\n<p>Although, as a firmware engineer, it is not easy to switch to a different product line, I believe that facing new challenges can help me to improve myself constantly. In the future, I hope I can learn and master new architectures quickly to become a valuable asset ASAP.</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"PoKai-Huang\"><a href=\"#PoKai-Huang\" class=\"headerlink\" title=\"PoKai Huang\"></a>PoKai Huang</h1><p>I am PoKai Huang, graduated from <a href=\"https://people.cs.nctu.edu.tw/~liweichan/\">Prof. Liwei Chan</a>‘s Lab, the Institute of Computer Science and Engineering of National Chiao Tung University (NCTU), in 2020. My research area is Human-Computer Interaction (HCI), mainly focused on exploring the possibility of novel interaction. My master thesis <strong>“Eliciting Gestures on One Ear as a Centralize, Deformable Touch Interface”</strong> explores the possibility of on-ear interaction, and has been submitted to <a href=\"https://chi2021.acm.org/\">CHI 2021</a>.<p></p>\n<p>I am a lively and enthusiastic person. In college, I have participated in many camps and clubs, and I served as an event leader to plan activities many times. Therefore, I am very familiar with communicating with a team and find compromises that everyone can agree on. Also, I have 6-7 years of tutoring experience, which has helped me to improve my communication skills.</p>\n<p>I have been working as a <strong>firmware engineer</strong> at SiliconMotion since 2021. During this time, I have developed security features according to <a href=\"https://trustedcomputinggroup.org/\">TCG</a> spec, customized requirements, and fixed various of firmware bugs. I have <u>modularized verification scripts to make developing new scripts easier</u>. Additionally, I have <u>extracted features from firmware and transplanted them into libraries</u>. I am also familiar with <u>Secure Boot Authentication</u> and <u>Firmware Update Verification</u>.</p>\n<p>Although, as a firmware engineer, it is not easy to switch to a different product line, I believe that facing new challenges can help me to improve myself constantly. In the future, I hope I can learn and master new architectures quickly to become a valuable asset ASAP.</p>\n"}],"PostAsset":[],"PostCategory":[],"PostTag":[],"Tag":[]}}